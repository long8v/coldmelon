{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 파일 입출력 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "import json\n",
    "import distutils.dir_util\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def write_json(data, fname):\n",
    "    def _conv(o):\n",
    "        if isinstance(o, np.int64) or isinstance(o, np.int32):\n",
    "            return int(o)\n",
    "        raise TypeError\n",
    "\n",
    "    parent = os.path.dirname(fname)\n",
    "    distutils.dir_util.mkpath(\"./\" + parent)\n",
    "    with io.open(\"./\" + fname, \"w\", encoding=\"utf8\") as f:\n",
    "        json_str = json.dumps(data, ensure_ascii=False, default=_conv)\n",
    "        f.write(json_str)\n",
    "\n",
    "\n",
    "def load_json(fname):\n",
    "    with open(fname, encoding='utf8') as f:\n",
    "        json_obj = json.load(f)\n",
    "\n",
    "    return json_obj\n",
    "\n",
    "\n",
    "def debug_json(r):\n",
    "    print(json.dumps(r, ensure_ascii=False, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as spr\n",
    "from collections import Counter\n",
    "\n",
    "song_meta = pd.read_json(\"./../data/song_meta.json\")\n",
    "train = pd.read_json(\"./../data/train.json\")\n",
    "test = pd.read_json(\"./../data/val.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터셋 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['istrain'] = 1\n",
    "test['istrain'] = 0\n",
    "\n",
    "n_train = len(train)\n",
    "n_test = len(test)\n",
    "\n",
    "# train + test\n",
    "plylst = pd.concat([train, test], ignore_index=True)\n",
    "\n",
    "# playlist id\n",
    "plylst[\"nid\"] = range(n_train + n_test)\n",
    "\n",
    "# id <-> nid\n",
    "plylst_id_nid = dict(zip(plylst[\"id\"],plylst[\"nid\"]))\n",
    "plylst_nid_id = dict(zip(plylst[\"nid\"],plylst[\"id\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# index 부여"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plylst_tag = plylst['tags']\n",
    "tag_counter = Counter([tg for tgs in plylst_tag for tg in tgs])\n",
    "tag_dict = {x: tag_counter[x] for x in tag_counter}\n",
    "\n",
    "tag_id_tid = dict()\n",
    "tag_tid_id = dict()\n",
    "for i, t in enumerate(tag_dict):\n",
    "    tag_id_tid[t] = i\n",
    "    tag_tid_id[i] = t\n",
    "\n",
    "n_tags = len(tag_dict)\n",
    "\n",
    "plylst_song = plylst['songs']\n",
    "song_counter = Counter([sg for sgs in plylst_song for sg in sgs])\n",
    "song_dict = {x: song_counter[x] for x in song_counter}\n",
    "\n",
    "song_id_sid = dict()\n",
    "song_sid_id = dict()\n",
    "for i, t in enumerate(song_dict):\n",
    "    song_id_sid[t] = i\n",
    "    song_sid_id[i] = t\n",
    "\n",
    "n_songs = len(song_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plylst['songs_id'] = plylst['songs'].map(lambda x: [song_id_sid.get(s) for s in x if song_id_sid.get(s) != None])\n",
    "plylst['tags_id'] = plylst['tags'].map(lambda x: [tag_id_tid.get(t) for t in x if tag_id_tid.get(t) != None])\n",
    "\n",
    "plylst_use = plylst[['istrain','nid','updt_date','songs_id','tags_id']]\n",
    "\n",
    "# 곡의 개수와 태그의 개수를 할당\n",
    "plylst_use.loc[:,'num_songs'] = plylst_use['songs_id'].map(len)\n",
    "plylst_use.loc[:,'num_tags'] = plylst_use['tags_id'].map(len)\n",
    "plylst_use = plylst_use.set_index('nid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "plylst_train = plylst_use.iloc[:n_train,:]\n",
    "plylst_test = plylst_use.iloc[n_train:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# csr (compressed sparse row matrix 생성)\n",
    "row = np.repeat(range(n_train), plylst_train['num_songs'])\n",
    "col = [song for songs in plylst_train['songs_id'] for song in songs]\n",
    "dat = np.repeat(1, plylst_train['num_songs'].sum())\n",
    "train_songs_A = spr.csr_matrix((dat, (row, col)), shape=(n_train, n_songs))\n",
    "\n",
    "row = np.repeat(range(n_train), plylst_train['num_tags'])\n",
    "col = [tag for tags in plylst_train['tags_id'] for tag in tags]\n",
    "dat = np.repeat(1, plylst_train['num_tags'].sum())\n",
    "train_tags_A = spr.csr_matrix((dat, (row, col)), shape=(n_train, n_tags))\n",
    "\n",
    "# csr (compressed sparse row matrix 생성)\n",
    "row = np.repeat(range(n_test), plylst_test['num_songs'])\n",
    "col = [song for songs in plylst_test['songs_id'] for song in songs]\n",
    "dat = np.repeat(1, plylst_test['num_songs'].sum())\n",
    "test_songs_A = spr.csr_matrix((dat, (row, col)), shape=(n_test, n_songs))\n",
    "\n",
    "row = np.repeat(range(n_test), plylst_test['num_tags'])\n",
    "col = [tag for tags in plylst_test['tags_id'] for tag in tags]\n",
    "dat = np.repeat(1, plylst_test['num_tags'].sum())\n",
    "test_tags_A = spr.csr_matrix((dat, (row, col)), shape=(n_test, n_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_merged_feature_csr = hstack([train_songs_A, train_tags_A])\n",
    "test_merged_feature_csr  = hstack([test_songs_A, test_tags_A])\n",
    "\n",
    "whole_datasets_csr       = vstack([train_merged_feature_csr, test_merged_feature_csr])\n",
    "whole_datasets_csr_T     = whole_datasets_csr.T.tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_datasets_csr_T.toarray().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from implicit.evaluation import  *\n",
    "from implicit.als import AlternatingLeastSquares as ALS\n",
    "from scipy.sparse import hstack, vstack\n",
    "\n",
    "n_factor = 128\n",
    "n_epoch  = 15.0\n",
    "\n",
    "als_model = ALS(factors=n_factor, regularization=0.08)\n",
    "als_model.fit(whole_datasets_csr_T * n_epoch)\n",
    "\n",
    "song_model = ALS(use_gpu=False)\n",
    "tag_model = ALS(use_gpu=False)\n",
    "song_model.user_factors = als_model.user_factors\n",
    "tag_model.user_factors = als_model.user_factors\n",
    "\n",
    "song_model.item_factors = als_model.item_factors[:n_songs]\n",
    "tag_model.item_factors  = als_model.item_factors[n_songs:]\n",
    "\n",
    "print(song_model.item_factors.shape)\n",
    "print(tag_model.item_factors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = []\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "for u in tqdm(range(test_merged_feature_csr.shape[0])):\n",
    "    song_rec = song_model.recommend(u, test_songs_A, N=100)\n",
    "    song_rec = [song_sid_id[x[0]] for x in test_songs_A]\n",
    "    \n",
    "    tag_rec = tag_model.recommend(u, test_tag_A, N=10)\n",
    "    tag_rec = [tag_tid_id[x[0]] for x in test_tag_A]\n",
    "    \n",
    "    res.append({\n",
    "            # train test의 vconcat 된 matrix에서 id를 추출하는 것이기 때문에 n_train 이후부터 test 데이터 셋임\n",
    "            # 따라서 u + n_train이 각각의 test 셋에서의 id\n",
    "            \"id\": plylst_nid_id[u + n_train],\n",
    "            \"songs\": song_rec,\n",
    "            \"tags\": tag_rec\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과 저장\n",
    "write_json(res, \"results.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

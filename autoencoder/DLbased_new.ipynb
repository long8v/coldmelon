{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from collections import Counter\n",
    "import torch\n",
    "from util.arena_util import load_json\n",
    "from util.arena_util import write_json\n",
    "import json\n",
    "# PyTorch imports\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from models import *\n",
    "from training import Trainer\n",
    "\n",
    "torch.manual_seed(0)\n",
    "# Workspace imports\n",
    "#from evaluate import evaluate_model\n",
    "#from utils import train_one_epoch, test, plot_statistics\n",
    "\n",
    "# Python imports\n",
    "import argparse\n",
    "from time import time\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _split_data(playlists):\n",
    "    tot = len(playlists)\n",
    "    train = playlists[:int(tot*0.80)]\n",
    "    val = playlists[int(tot*0.80):]\n",
    "\n",
    "    return train, val\n",
    "def _mask(playlists, mask_cols, del_cols):\n",
    "    q_pl = copy.deepcopy(playlists)\n",
    "    a_pl = copy.deepcopy(playlists)\n",
    "\n",
    "    for i in range(len(playlists)):\n",
    "        for del_col in del_cols:\n",
    "            q_pl[i][del_col] = []\n",
    "            if del_col == 'songs':\n",
    "                a_pl[i][del_col] = a_pl[i][del_col][:100]\n",
    "            elif del_col == 'tags':\n",
    "                a_pl[i][del_col] = a_pl[i][del_col][:10]\n",
    "\n",
    "        for col in mask_cols:\n",
    "            mask_len = len(playlists[i][col])\n",
    "            mask = np.full(mask_len, False)\n",
    "            mask[:mask_len//2] = True\n",
    "            np.random.shuffle(mask)\n",
    "\n",
    "            q_pl[i][col] = list(np.array(q_pl[i][col])[mask])\n",
    "            a_pl[i][col] = list(np.array(a_pl[i][col])[np.invert(mask)])\n",
    "\n",
    "    return q_pl, a_pl\n",
    "\n",
    "def _mask_data(playlists):\n",
    "    playlists = copy.deepcopy(playlists)\n",
    "    tot = len(playlists)\n",
    "    # song_only = playlists[:int(tot * 0.3)]\n",
    "    # song_and_tags = playlists[int(tot * 0.3):int(tot * 0.8)]\n",
    "    # tags_only = playlists[int(tot * 0.8):int(tot * 0.95)]\n",
    "    # title_only = playlists[int(tot * 0.95):]\n",
    "    song_only = playlists[:int(tot * 0.4)]\n",
    "    song_and_tags = playlists[int(tot * 0.4):]\n",
    "\n",
    "    # print(f\"Total: {len(playlists)}, \"\n",
    "    #         f\"Song only: {len(song_only)}, \"\n",
    "    #         f\"Song & Tags: {len(song_and_tags)}, \"\n",
    "    #         f\"Tags only: {len(tags_only)}, \"\n",
    "    #         f\"Title only: {len(title_only)}\")\n",
    "\n",
    "    print(f\"Total: {len(playlists)}, \"\n",
    "            f\"Song only: {len(song_only)}, \"\n",
    "            f\"Song & Tags: {len(song_and_tags)}\"\n",
    "            )\n",
    "\n",
    "    song_q, song_a = _mask(song_only, ['songs'], ['tags'])\n",
    "    songtag_q, songtag_a = _mask(song_and_tags, ['songs', 'tags'], [])\n",
    "    # tag_q, tag_a = _mask(tags_only, ['tags'], ['songs'])\n",
    "    # title_q, title_a = _mask(title_only, [], ['songs', 'tags'])\n",
    "\n",
    "    q = song_q + songtag_q #+ tag_q + title_q\n",
    "    a = song_a + songtag_a #+ tag_a + title_a\n",
    "\n",
    "    shuffle_indices = np.arange(len(q))\n",
    "    np.random.shuffle(shuffle_indices)\n",
    "\n",
    "    q = list(np.array(q)[shuffle_indices])\n",
    "    a = list(np.array(a)[shuffle_indices])\n",
    "\n",
    "    return q, a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##train = pd.read_json('../file/train.json', encoding='utf-8')\n",
    "#song_meta = pd.read_json('../file/song_meta.json', encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Reading data...\n\nTotal playlists: 115071\n"
    }
   ],
   "source": [
    "random.seed(777)\n",
    "fname = '../file/train.json'\n",
    "print(\"Reading data...\\n\")\n",
    "playlists = load_json(fname)\n",
    "random.shuffle(playlists)\n",
    "print(f\"Total playlists: {len(playlists)}\")\n",
    "\n",
    "# print(\"Splitting data...\")\n",
    "# train, val = _split_data(playlists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Total: 115071, Song only: 46028, Song & Tags: 69043\n115071 115071\n"
    }
   ],
   "source": [
    "train_q, train_a = _mask_data(playlists)\n",
    "print(len(train_q),len(train_a))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Masked...\n"
    }
   ],
   "source": [
    "print(\"Masked...\")\n",
    "write_json(train_q, \"train_q_new.json\")\n",
    "write_json(train_a, \"train_a_new.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "plylst = pd.read_json('../file/train.json', encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "         tags      id                 plylst_title     songs  like_cnt  \\\n104492  [OST]  108909  하드코어 일렉트로니카의 전설 The Prodigy  [660089]       422   \n\n                      updt_date  \n104492  2010-01-05 18:21:19.000  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tags</th>\n      <th>id</th>\n      <th>plylst_title</th>\n      <th>songs</th>\n      <th>like_cnt</th>\n      <th>updt_date</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>104492</th>\n      <td>[OST]</td>\n      <td>108909</td>\n      <td>하드코어 일렉트로니카의 전설 The Prodigy</td>\n      <td>[660089]</td>\n      <td>422</td>\n      <td>2010-01-05 18:21:19.000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "plylst[plylst['plylst_title']==\"하드코어 일렉트로니카의 전설 The Prodigy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "5285871"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "plylst[\"songs\"].apply(lambda a: len(a)).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "5285871"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "plylst[\"songs_id\"].apply(lambda a: len(a)).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "3582412"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "plylst[\"songs_id_20\"].apply(lambda a: len(a)).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "4062146"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "plylst[\"songs_id_10\"].apply(lambda a: len(a)).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(2158387, 1903759, 1223725)"
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "plylst[\"songs_id_100\"].apply(lambda a: len(a)).sum(), plylst[\"songs_id_10_100\"].apply(lambda a: len(a)).sum(), plylst[\"songs_id_0_10\"].apply(lambda a: len(a)).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_q = load_json('arena_data/train_q_new.json')\n",
    "#train_a = load_json('arena_data/train_a_new.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "plylst_tag = plylst['tags']\n",
    "tag_counter = Counter([tg for tgs in plylst_tag for tg in tgs])\n",
    "tag_dict = {x: tag_counter[x] for x in tag_counter}\n",
    "\n",
    "tag_id_tid = dict()\n",
    "tag_tid_id = dict()\n",
    "for i, t in enumerate(tag_dict):\n",
    "    tag_id_tid[t] = i\n",
    "    tag_tid_id[i] = t\n",
    "\n",
    "n_tags = len(tag_dict)\n",
    "\n",
    "plylst_song = plylst['songs']\n",
    "#song_selected = [_[0] for _ in list(filter(lambda e: e[1] > 100, Counter(songs).items()))]\n",
    "song_counter = Counter([sg for sgs in plylst_song for sg in sgs])\n",
    "song_dict = {x: song_counter[x] for x in song_counter}\n",
    "\n",
    "song_dict_100 = {x: song_counter[x] for x in song_counter if song_counter[x]>100}\n",
    "song_dict_10_100 = {x: song_counter[x] for x in song_counter if 10 < song_counter[x] <= 100}\n",
    "song_dict_10 = {x: song_counter[x] for x in song_counter if song_counter[x]>10}\n",
    "song_dict_0_10 = {x: song_counter[x] for x in song_counter if song_counter[x] <= 10}\n",
    "song_dict_20 = {x: song_counter[x] for x in song_counter if song_counter[x]>20}\n",
    "\n",
    "song_id_sid = dict()\n",
    "song_sid_id = dict()\n",
    "\n",
    "song_100_id_sid = dict()\n",
    "song_100_sid_id = dict()\n",
    "\n",
    "song_10_id_sid = dict()\n",
    "song_10_sid_id = dict()\n",
    "\n",
    "song_20_id_sid = dict()\n",
    "song_20_sid_id = dict()\n",
    "\n",
    "song_10_100_id_sid = dict()\n",
    "song_10_100_sid_id = dict()\n",
    "\n",
    "song_0_10_id_sid = dict()\n",
    "song_0_10_sid_id = dict()\n",
    "\n",
    "for i, t in enumerate(song_dict):\n",
    "    song_id_sid[t] = i\n",
    "    song_sid_id[i] = t\n",
    "\n",
    "for i, t in enumerate(song_dict_100):\n",
    "    song_100_id_sid[t] = i\n",
    "    song_100_sid_id[i] = t\n",
    "\n",
    "for i, t in enumerate(song_dict_10):\n",
    "    song_10_id_sid[t] = i\n",
    "    song_10_sid_id[i] = t\n",
    "\n",
    "for i, t in enumerate(song_dict_20):\n",
    "    song_20_id_sid[t] = i\n",
    "    song_20_sid_id[i] = t\n",
    "\n",
    "for i, t in enumerate(song_dict_10_100):\n",
    "    song_10_100_id_sid[t] = i\n",
    "    song_10_100_sid_id[i] = t\n",
    "\n",
    "for i, t in enumerate(song_dict_0_10):\n",
    "    song_0_10_id_sid[t] = i\n",
    "    song_0_10_sid_id[i] = t\n",
    "\n",
    "\n",
    "n_songs = len(song_dict)\n",
    "n_songs_100 = len(song_dict_100)\n",
    "n_songs_10 = len(song_dict_10)\n",
    "n_songs_20 = len(song_dict_20)\n",
    "n_songs_10_100 = len(song_dict_10_100)\n",
    "n_songs_0_10 = len(song_dict_0_10)\n",
    "n_plylst = len(plylst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(615142, 8491, 66587, 540064)"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "n_songs, n_songs_100, n_songs_10_100, n_songs_0_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "plylst['songs_id_10'] = plylst['songs'].map(lambda x: [song_10_id_sid.get(s) for s in x if song_10_id_sid.get(s) != None])\n",
    "plylst['songs_id_20'] = plylst['songs'].map(lambda x: [song_20_id_sid.get(s) for s in x if song_20_id_sid.get(s) != None])\n",
    "plylst['songs_id'] = plylst['songs'].map(lambda x: [song_id_sid.get(s) for s in x if song_id_sid.get(s) != None])\n",
    "plylst['songs_id_100'] = plylst['songs'].map(lambda x: [song_100_id_sid.get(s) for s in x if song_100_id_sid.get(s) != None])\n",
    "\n",
    "plylst['songs_id_10_100'] = plylst['songs'].map(lambda x: [song_10_100_id_sid.get(s) for s in x if song_10_100_id_sid.get(s) != None])\n",
    "plylst['songs_id_0_10'] = plylst['songs'].map(lambda x: [song_0_10_id_sid.get(s) for s in x if song_0_10_id_sid.get(s) != None])\n",
    "\n",
    "plylst['tags_id'] = plylst['tags'].map(lambda x: [tag_id_tid.get(t) for t in x if tag_id_tid.get(t) != None])\n",
    "\n",
    "plylst['songs_id_hier'] = plylst['songs'].map(lambda x: [[0,song_100_id_sid.get(s)] if song_100_id_sid.get(s) != None else [1,song_10_100_id_sid.get(s)] if song_10_100_id_sid.get(s) != None else [2,song_0_10_id_sid.get(s)] for s in x ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_list = plylst[plylst[\"songs_id_20\"].apply(lambda a: len(a)>0)*plylst[\"songs_id_20\"].apply(lambda a: len(a)>0)][\"songs_id_20\"].tolist()\n",
    "\n",
    "# train_list_100 = plylst[plylst[\"songs_id_100\"].apply(lambda a: len(a)>0)][\"songs_id_100\"].tolist()\n",
    "\n",
    "# train_list_10_100 = plylst[plylst[\"songs_id_10_100\"].apply(lambda a: len(a)>0)][\"songs_id_10_100\"].tolist()\n",
    "\n",
    "# train_list_0_10 = plylst[plylst[\"songs_id_0_10\"].apply(lambda a: len(a)>0)][\"songs_id_0_10\"].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_list = plylst[plylst['songs_id_hier'].apply(lambda a: 0 in np.array(a)[:,0] and 1 in np.array(a)[:,0] and 2 in np.array(a)[:,0])]['songs_id_hier'].tolist()\n",
    "\n",
    "train_list_a = plylst[plylst['songs_id_hier'].apply(lambda a: 0 in np.array(a)[:,0] and 1 in np.array(a)[:,0] and 2 in np.array(a)[:,0])]['songs_id'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(79409, 79409)"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "len(train_list), len(train_list_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "29160 615142\n"
    }
   ],
   "source": [
    "# print(n_songs_100)\n",
    "n_tags = len(tag_dict)\n",
    "print(n_tags, n_songs)\n",
    "#print(len(train_list_100),len(train_list_10_100),len(train_list_0_10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "MLP5(\n  (song_embedding_100): Embedding(8491, 774)\n  (song_embedding_10_100): Embedding(66587, 387)\n  (song_embedding_0_10): Embedding(540064, 387)\n  (fc_layers): ModuleList(\n    (0): Linear(in_features=1548, out_features=512, bias=True)\n    (1): Linear(in_features=512, out_features=256, bias=True)\n  )\n  (output_layer): Linear(in_features=256, out_features=615142, bias=True)\n)"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "from models import *\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = MLP5(n_tags, n_songs_100, n_songs_10_100, n_songs_0_10, layers=[1548, 512, 256], dropout=False, use_cuda = True)\n",
    "if torch.cuda.device_count() > 1:\n",
    "    model = nn.DataParallel(model)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #from models import MLP\n",
    "# os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'\n",
    "# # device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# model = MLP(n_tags, n_songs_20, layers=[4096, 2048, 6192], dropout=False, use_cuda = True)\n",
    "# if torch.cuda.device_count() > 1:\n",
    "#     model = nn.DataParallel(model)\n",
    "# model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(\"./output_model_epoch_0.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<All keys matched successfully>"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "model.load_state_dict(checkpoint['model_state_dict'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "MLP4(\n  (song_embedding): Embedding(42109, 1024)\n  (fc_layers): ModuleList(\n    (0): Linear(in_features=1024, out_features=512, bias=True)\n    (1): Linear(in_features=512, out_features=256, bias=True)\n    (2): Linear(in_features=256, out_features=512, bias=True)\n    (3): Linear(in_features=512, out_features=256, bias=True)\n    (4): Linear(in_features=256, out_features=128, bias=True)\n    (5): Linear(in_features=128, out_features=256, bias=True)\n    (6): Linear(in_features=256, out_features=128, bias=True)\n    (7): Linear(in_features=128, out_features=256, bias=True)\n    (8): Linear(in_features=256, out_features=512, bias=True)\n    (9): Linear(in_features=512, out_features=256, bias=True)\n    (10): Linear(in_features=256, out_features=512, bias=True)\n    (11): Linear(in_features=512, out_features=256, bias=True)\n    (12): Linear(in_features=256, out_features=512, bias=True)\n    (13): Linear(in_features=512, out_features=256, bias=True)\n    (14): Linear(in_features=256, out_features=512, bias=True)\n    (15): Linear(in_features=512, out_features=256, bias=True)\n    (16): Linear(in_features=256, out_features=512, bias=True)\n    (17): Linear(in_features=512, out_features=1024, bias=True)\n    (18): Linear(in_features=1024, out_features=2048, bias=True)\n    (19): Linear(in_features=2048, out_features=4096, bias=True)\n  )\n  (output_layer): Linear(in_features=4096, out_features=42109, bias=True)\n)"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "from models import *\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = MLP4(n_tags, n_songs_20, layers=[1024, 512, 256, 512, 256, 128, 256, 128, 256, 512, 256, 512, 256, 512, 256, 512, 256, 512, 1024, 2048, 4096], dropout=False, use_cuda = True)\n",
    "if torch.cuda.device_count() > 1:\n",
    "    model = nn.DataParallel(model)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "MLP2(\n  (song_embedding): Embedding(42109, 1024)\n  (fc_layers): ModuleList(\n    (0): Linear(in_features=1024, out_features=512, bias=True)\n    (1): Linear(in_features=512, out_features=256, bias=True)\n    (2): Linear(in_features=256, out_features=512, bias=True)\n    (3): Linear(in_features=512, out_features=256, bias=True)\n    (4): Linear(in_features=256, out_features=128, bias=True)\n    (5): Linear(in_features=128, out_features=256, bias=True)\n    (6): Linear(in_features=256, out_features=128, bias=True)\n    (7): Linear(in_features=128, out_features=256, bias=True)\n    (8): Linear(in_features=256, out_features=512, bias=True)\n    (9): Linear(in_features=512, out_features=256, bias=True)\n    (10): Linear(in_features=256, out_features=512, bias=True)\n    (11): Linear(in_features=512, out_features=256, bias=True)\n    (12): Linear(in_features=256, out_features=512, bias=True)\n    (13): Linear(in_features=512, out_features=256, bias=True)\n    (14): Linear(in_features=256, out_features=512, bias=True)\n    (15): Linear(in_features=512, out_features=256, bias=True)\n    (16): Linear(in_features=256, out_features=512, bias=True)\n    (17): Linear(in_features=512, out_features=1024, bias=True)\n    (18): Linear(in_features=1024, out_features=2048, bias=True)\n  )\n  (output_layer): Linear(in_features=2048, out_features=42109, bias=True)\n)"
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "#from models import MLP1\n",
    "from models import *\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = MLP2(n_tags, n_songs_20, layers=[1024, 512, 256, 512, 256, 128, 256, 128, 256, 512, 256, 512, 256, 512, 256, 512, 256, 512, 1024, 2048], dropout=False, use_cuda = True)\n",
    "if torch.cuda.device_count() > 1:\n",
    "    model = nn.DataParallel(model)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "# Dataset 상속\n",
    "class CustomDataset(Dataset): \n",
    "  def __init__(self, xinput, yinput):\n",
    "    self.x_data = xinput\n",
    "    self.y_data = yinput\n",
    "    # self.batch_size = batchsize\n",
    "\n",
    "  # 총 데이터의 개수를 리턴\n",
    "  def __len__(self): \n",
    "    return len(self.x_data)\n",
    "\n",
    "  # 인덱스를 입력받아 그에 맵핑되는 입출력 데이터를 파이토치의 Tensor 형태로 리턴\n",
    "  def __getitem__(self, idx): \n",
    "    # device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    # x = torch.LongTensor(self.x_data[idx]).to(device)\n",
    "    # y = torch.LongTensor(self.y_data[idx]).to(device)\n",
    "    x = torch.LongTensor(self.x_data[idx])\n",
    "    y = torch.LongTensor(self.y_data[idx])\n",
    "    return {\"input\": x, \"label\": y}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_batch(samples):\n",
    "    inputs = [sample['input'] for sample in samples]\n",
    "    inputs = torch.nn.utils.rnn.pad_sequence(inputs, batch_first=True, padding_value = n_songs_20)\n",
    "    labels = [sample['label'] for sample in samples]\n",
    "    labels = torch.nn.utils.rnn.pad_sequence(labels, batch_first=True, padding_value = n_songs_20)\n",
    "    # padded_inputs = torch.nn.utils.rnn.pad_sequence(inputs, batch_first=True)\n",
    "    return {'input': inputs,\n",
    "            'label': labels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = CustomDataset(train_list, train_list_a)\n",
    "dataloader = DataLoader(input, batch_size=1, collate_fn=make_batch, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 798.00 MiB (GPU 0; 11.00 GiB total capacity; 9.37 GiB already allocated; 346.50 MiB free; 9.40 GiB reserved in total by PyTorch)",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-f02dc5464bf1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m                  \u001b[0mrecord_loss_every\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                  use_cuda = True)\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\hscho\\coldmelon\\autoencoder\\training.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, data_loader, epochs, save_training_gif)\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m             \u001b[0mepoch_train_start\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m             \u001b[0mmean_epoch_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmean_epoch_ndcg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmean_epoch_loss_recon\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmean_epoch_loss_embed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_epoch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     76\u001b[0m             print('Epoch: {} Average loss: {:.2f} Average ndcg: {:.2f} Average recon_loss: {:.2f} Average embed_loss: {:.2f} Training time: {:.2f}'.format(epoch + 1,\n\u001b[0;32m     77\u001b[0m                                                           \u001b[0mmean_epoch_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmean_epoch_ndcg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmean_epoch_loss_recon\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmean_epoch_loss_embed\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\hscho\\coldmelon\\autoencoder\\training.py\u001b[0m in \u001b[0;36m_train_epoch\u001b[1;34m(self, data_loader)\u001b[0m\n\u001b[0;32m    108\u001b[0m             \u001b[1;31m# data = data.to(device)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m             \u001b[1;31m# label = label.to(device)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 110\u001b[1;33m             \u001b[0miter_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mndcg_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miter_loss_recon\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miter_loss_embed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_iteration\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdatas\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    111\u001b[0m             \u001b[0mepoch_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0miter_loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m             \u001b[0mepoch_ndcg\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mndcg_loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\hscho\\coldmelon\\autoencoder\\training.py\u001b[0m in \u001b[0;36m_train_iteration\u001b[1;34m(self, datas)\u001b[0m\n\u001b[0;32m    169\u001b[0m         \u001b[0mndcg_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ndcg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moutput_recon\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    170\u001b[0m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 171\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    172\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m         \u001b[0mtrain_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\myvae\\lib\\site-packages\\torch\\optim\\adam.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    101\u001b[0m                     \u001b[0mdenom\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmax_exp_avg_sq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'eps'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 103\u001b[1;33m                     \u001b[0mdenom\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mexp_avg_sq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'eps'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m                 \u001b[0mstep_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'lr'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mbias_correction1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 798.00 MiB (GPU 0; 11.00 GiB total capacity; 9.37 GiB already allocated; 346.50 MiB free; 9.40 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(model, optimizer, n_songs_100 + n_songs_10_100 + n_songs_0_10,\n",
    "                 print_loss_every=100,\n",
    "                 record_loss_every=5,\n",
    "                 use_cuda = True)\n",
    "trainer.train(dataloader, epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({'epoch': 0, 'model_state_dict': model.state_dict(), 'optimizer_state_dict': optimizer.state_dict()},\"./output_model_epoch_0.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_json = load_json('../file/val.json')\n",
    "val_json_1 = load_json(\"../file/results.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_seen(seen, l):\n",
    "    seen = set(seen)\n",
    "    return [x for x in l if not (x in seen)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0\n500\n1000\n1500\n2000\n2500\n3000\n3500\n4000\n4500\n5000\n5500\n6000\n6500\n7000\n7500\n8000\n8500\n9000\n9500\n10000\n10500\n11000\n11500\n12000\n12500\n13000\n13500\n14000\n14500\n15000\n15500\n16000\n16500\n17000\n17500\n18000\n18500\n19000\n19500\n20000\n20500\n21000\n21500\n22000\n22500\n23000\n"
    }
   ],
   "source": [
    "for idx, plst in enumerate(val_json):\n",
    "    if len(plst['songs']) !=0 :\n",
    "        tmp=np.array(list(map(lambda s: [0,song_100_id_sid.get(s)] if song_100_id_sid.get(s) != None else [1,song_10_100_id_sid.get(s)] if song_10_100_id_sid.get(s) != None else [2,song_0_10_id_sid.get(s)] if song_0_10_id_sid.get(s) != None else [615142,615142], plst['songs'])))\n",
    "        ipp = [torch.from_numpy(tmp[tmp!=[615142,615142]].reshape(-1,2)).to(dtype = torch.long, device = device)]\n",
    "        #print(ipp.shape)\n",
    "        output = model.predict(ipp)\n",
    "        rec_song_idx = [song_sid_id[i] for i in output]\n",
    "        rec_song_idx = remove_seen(plst['songs'],rec_song_idx)\n",
    "        rec_song_idx = rec_song_idx[:100]\n",
    "        val_json_1[idx]['songs']=rec_song_idx\n",
    "    if idx % 500 == 0 :\n",
    "        print(idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([375205, 403509, 302814, 577464, 110804, 120282,  53468, 429662,\n        46894, 187353,  84157,  24355, 313185, 104931, 451993, 307118,\n       182369, 450387, 377740, 595349, 543041,  58227, 471478, 605504,\n        28907, 406451, 529940, 524900, 106554, 397420,  37860, 146677,\n       114593, 126908, 581766, 502784, 291339, 423164,  85924, 152538,\n       409752, 226754,      0,  95480, 304912, 444864,  84648, 556605,\n       387161, 431915, 566758, 136839, 212922,  37388, 187268, 557458,\n       345563, 434584, 101344, 375776, 213192, 610982, 548901, 598822,\n       235126, 466859, 145443, 366366, 449636, 281114, 514351, 348241,\n       588003, 289977, 450049, 510930, 178832, 367905, 372123, 279450,\n       523010, 556609, 594090, 520071,  79168, 515996, 452334, 514259,\n       242194, 475587, 167449, 584090, 273474,  34799, 474495,      1,\n       197197, 288069, 127896, 593605, 359027, 445257, 419149, 503400,\n       214592, 322273, 568653, 597565, 461940, 297482, 385187, 220822,\n       490448, 430910, 302640, 538554, 513327, 240424,  40300, 513119,\n       563584, 563658, 192900, 195891, 262561, 482831, 576574, 179003,\n       507455, 228889, 610502, 104264,  66891, 555177, 310127, 193182,\n       412778, 510991, 288304, 312230, 136871,      2, 303363, 481681,\n       152297,      3, 423853, 578293, 313772,  95823, 148735, 301298,\n       587404, 106885, 183722, 156134, 373736, 331067, 513099, 186397,\n       357011, 249684, 384212, 613553, 493319, 473163,  88046, 614515,\n       147565, 265451,  67937, 531548, 173111, 184112, 538501, 534575,\n            4, 609858, 338337, 571735,  91227, 415660, 228712, 463072,\n       303463, 493066, 376637,  54435, 278631, 197751, 193483,  73328,\n       613824, 210144, 125398, 127394, 575469, 375765, 580098,  53730],\n      dtype=int64)"
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[tensor([[    0,  4299],\n         [    0,  1498],\n         [    0,  3404],\n         [    0,  5061],\n         [    0,  2919],\n         [    0,  1506],\n         [    0,  1518],\n         [    0,  2252],\n         [    0,  2870],\n         [    1, 18259],\n         [    1, 20741],\n         [    0,  1513],\n         [    0,  1514],\n         [    1, 28290],\n         [    0,   522],\n         [    0,  6394],\n         [    0,  7331],\n         [    0,  1270],\n         [    0,  1497],\n         [    0,  7686]], device='cuda:0')]"
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "ipp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_json(val_json_1, \"./year_genre_onehot/results.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([[[     1,  17608],\n         [     0,   5097],\n         [     2,   2474],\n         [     2, 480139],\n         [     2, 390715],\n         [     2, 480140],\n         [     2, 480141],\n         [     2, 480142],\n         [     2, 480143],\n         [     1,  33522],\n         [     2, 480144],\n         [     2, 480145],\n         [     2, 480146],\n         [     2, 411721]]])\n1\n=======\ntensor([[ 39421,  18188,   9378, 555217, 465793, 555218, 555219, 555220, 555221,\n          76691, 555222, 555223, 555224, 486799]])\n"
    }
   ],
   "source": [
    "for x in dataloader:\n",
    "    data, label = x['input'], x['label']\n",
    "    print(data)\n",
    "    print(len(data))\n",
    "    print(\"=======\")\n",
    "    print(label)\n",
    "    break   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, plst in enumerate(val_json):\n",
    "    if len(plst['songs']) !=0 :\n",
    "        tmp=np.array(list(map(lambda s: [0,song_100_id_sid.get(s)] if song_100_id_sid.get(s) != None else [1,song_10_100_id_sid.get(s)] if song_10_100_id_sid.get(s) != None else [2,song_0_10_id_sid.get(s)] if song_0_10_id_sid.get(s) != None else [615142,615142], plst['songs'])))\n",
    "        torch.from_numpy(tmp[tmp!=[615142,615142]].reshape(-1,2)).to(dtype = torch.long, device = device)\n",
    "    if idx == 5:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, plst in enumerate(val_json):\n",
    "    if len(plst['songs']) !=0 :\n",
    "        ipp = np.array([[song_20_id_sid.get(i) for i in val_json[idx]['songs'] if song_20_id_sid.get(i) != None]])\n",
    "        output = model.predict(ipp)\n",
    "        output = output[np.isin(output, ipp[0]) == False][:100]\n",
    "        rec_song_idx = [song_20_sid_id[i] for i in output]\n",
    "        val_json_1[idx]['songs']=rec_song_idx\n",
    "    if idx % 500 == 0 :\n",
    "        print(idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# CUDA for PyTorch\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "# cudnn.benchmark = True\n",
    "\n",
    "\n",
    "def main():\n",
    "\n",
    "    args = parse_args()\n",
    "    path = args.path\n",
    "    dataset = args.dataset\n",
    "    layers = eval(args.layers)\n",
    "    weight_decay = args.weight_decay\n",
    "    num_negatives_train = args.num_neg_train\n",
    "    num_negatives_test = args.num_neg_test\n",
    "    dropout = args.dropout\n",
    "    learner = args.learner\n",
    "    learning_rate = args.lr\n",
    "    batch_size = args.batch_size\n",
    "    epochs = args.epochs\n",
    "    verbose = args.verbose\n",
    "\n",
    "    topK = 100\n",
    "    print(\"MLP arguments: %s \" % (args))\n",
    "    # model_out_file = 'Pretrain/%s_MLP_%s_%d.h5' %(args.dataset, args.layers, time())\n",
    "\n",
    "    # Load data\n",
    "\n",
    "    t1 = time()\n",
    "    full_dataset = CustomDataset(train_q_list, train_a_list)\n",
    "\n",
    "    train_data_q, train_data_a = full_dataset.x_data, full_dataset.y_data\n",
    "    num_data = len(full_dataset)\n",
    "\n",
    "    print(\"Load data done [%.1f s]. #user=%d, #item=%d\"\n",
    "          % (time()-t1, num_data, n_songs_100))\n",
    "    \n",
    "    #dataloader = DataLoader(dataset, batch_size=2, shuffle=True)\n",
    "    \n",
    "    training_data_generator = DataLoader(\n",
    "        full_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "\n",
    "    # Build model\n",
    "    model = MLP(num_data, n_songs_100, layers=layers, dropout=dropout)\n",
    "    # Transfer the model to GPU, if one is available\n",
    "    model.to(device)\n",
    "    if verbose:\n",
    "        print(model)\n",
    "\n",
    "    loss_fn = torch.nn.BCELoss()\n",
    "    # Use Adam optimizer\n",
    "    optimizer = torch.optim.Adam(model.parameters(), weight_decay=weight_decay)\n",
    "\n",
    "    # Record performance\n",
    "    hr_list = []\n",
    "    ndcg_list = []\n",
    "    BCE_loss_list = []\n",
    "\n",
    "    # Check Init performance\n",
    "    hr, ndcg = test(model, full_dataset, topK)\n",
    "    hr_list.append(hr)\n",
    "    ndcg_list.append(ndcg)\n",
    "    BCE_loss_list.append(1)\n",
    "    # do the epochs now\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss = train_one_epoch( model, training_data_generator, loss_fn, optimizer, epoch, device)\n",
    "\n",
    "        if epoch % verbose == 0:\n",
    "            hr, ndcg = test(model, full_dataset, topK)\n",
    "            hr_list.append(hr)\n",
    "            ndcg_list.append(ndcg)\n",
    "            BCE_loss_list.append(epoch_loss)\n",
    "            # if hr > best_hr:\n",
    "            #     best_hr, best_ndcg, best_iter = hr, ndcg, epoch\n",
    "            #     if args.out > 0:\n",
    "            #         model.save(model_out_file, overwrite=True)\n",
    "    print(\"hr for epochs: \", hr_list)\n",
    "    print(\"ndcg for epochs: \", ndcg_list)\n",
    "    print(\"loss for epochs: \", BCE_loss_list)\n",
    "    # plot_statistics(hr_list, ndcg_list, BCE_loss_list,model.get_alias(), \"./figs\")\n",
    "    # with open(\"metrics\", 'wb') as fp:\n",
    "    #     pickle.dump(hr_list, fp)\n",
    "    #     pickle.dump(ndcg_list, fp)\n",
    "\n",
    "    best_iter = np.argmax(np.array(hr_list))\n",
    "    best_hr = hr_list[best_iter]\n",
    "    best_ndcg = ndcg_list[best_iter]\n",
    "    print(\"End. Best Iteration %d:  HR = %.4f, NDCG = %.4f. \" %\n",
    "          (best_iter, best_hr, best_ndcg))\n",
    "    # if args.out > 0:\n",
    "    #     print(\"The best MLP model is saved to %s\" %(model_out_file))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Device available: {}\".format(device))\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38164bitmyvaeconda7da6165c86c1489985b6c099d771d710",
   "display_name": "Python 3.8.1 64-bit ('myvae': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
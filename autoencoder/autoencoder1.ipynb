{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_json('../file/train.json', encoding='utf-8')\n",
    "song_meta = pd.read_json('../file/song_meta.json', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                                                     tags      id  \\\n0                                                     [락]   61281   \n1                                                [추억, 회상]   10532   \n2                                               [까페, 잔잔한]   76951   \n3       [연말, 눈오는날, 캐럴, 분위기, 따듯한, 크리스마스캐럴, 겨울노래, 크리스마스,...  147456   \n4                                                    [댄스]   27616   \n...                                                   ...     ...   \n115066               [록메탈, 밴드사운드, 록, 락메탈, 메탈, 락, extreme]  120325   \n115067                                               [일렉]  106976   \n115068             [담시, 가족, 눈물, 그리움, 주인공, 나의_이야기, 사랑, 친구]   11343   \n115069                      [잔잔한, 버스, 퇴근버스, Pop, 풍경, 퇴근길]  131982   \n115070                             [노래추천, 팝송추천, 팝송, 팝송모음]  100389   \n\n                             plylst_title  \\\n0                                 여행같은 음악   \n1                                 요즘 너 말야   \n2                   편하게, 잔잔하게 들을 수 있는 곡.-   \n3                   크리스마스 분위기에 흠뻑 취하고 싶을때   \n4                                추억의 노래 ㅋ   \n...                                   ...   \n115066                      METAL E'SM #2   \n115067     빠른 리스너를 위한 따끈따끈한 최신 인기 EDM 모음!   \n115068              #1. 눈물이 앞을 가리는 나의_이야기   \n115069  퇴근 버스에서 편히 들으면서 하루를 마무리하기에 좋은 POP   \n115070                FAVORITE POPSONG!!!   \n\n                                                    songs  like_cnt  \\\n0       [525514, 129701, 383374, 562083, 297861, 13954...        71   \n1       [432406, 675945, 497066, 120377, 389529, 24427...         1   \n2       [83116, 276692, 166267, 186301, 354465, 256598...        17   \n3       [394031, 195524, 540149, 287984, 440773, 10033...        33   \n4       [159327, 553610, 5130, 645103, 294435, 100657,...         9   \n...                                                   ...       ...   \n115066  [429629, 441511, 612106, 516359, 691768, 38714...         3   \n115067  [321330, 216057, 534472, 240306, 331098, 23288...        13   \n115068  [50512, 249024, 250608, 371171, 229942, 694943...         4   \n115069  [533534, 608114, 343608, 417140, 609009, 30217...         4   \n115070  [26008, 456354, 324105, 89871, 135272, 143548,...        17   \n\n                      updt_date  \n0       2013-12-19 18:36:19.000  \n1       2014-12-02 16:19:42.000  \n2       2017-08-28 07:09:34.000  \n3       2019-12-05 15:15:18.000  \n4       2011-10-25 13:54:56.000  \n...                         ...  \n115066  2020-04-17 04:31:11.000  \n115067  2015-12-24 17:23:19.000  \n115068  2019-08-16 20:59:22.000  \n115069  2019-10-25 23:40:42.000  \n115070  2020-04-18 20:35:06.000  \n\n[115071 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tags</th>\n      <th>id</th>\n      <th>plylst_title</th>\n      <th>songs</th>\n      <th>like_cnt</th>\n      <th>updt_date</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[락]</td>\n      <td>61281</td>\n      <td>여행같은 음악</td>\n      <td>[525514, 129701, 383374, 562083, 297861, 13954...</td>\n      <td>71</td>\n      <td>2013-12-19 18:36:19.000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[추억, 회상]</td>\n      <td>10532</td>\n      <td>요즘 너 말야</td>\n      <td>[432406, 675945, 497066, 120377, 389529, 24427...</td>\n      <td>1</td>\n      <td>2014-12-02 16:19:42.000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[까페, 잔잔한]</td>\n      <td>76951</td>\n      <td>편하게, 잔잔하게 들을 수 있는 곡.-</td>\n      <td>[83116, 276692, 166267, 186301, 354465, 256598...</td>\n      <td>17</td>\n      <td>2017-08-28 07:09:34.000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[연말, 눈오는날, 캐럴, 분위기, 따듯한, 크리스마스캐럴, 겨울노래, 크리스마스,...</td>\n      <td>147456</td>\n      <td>크리스마스 분위기에 흠뻑 취하고 싶을때</td>\n      <td>[394031, 195524, 540149, 287984, 440773, 10033...</td>\n      <td>33</td>\n      <td>2019-12-05 15:15:18.000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[댄스]</td>\n      <td>27616</td>\n      <td>추억의 노래 ㅋ</td>\n      <td>[159327, 553610, 5130, 645103, 294435, 100657,...</td>\n      <td>9</td>\n      <td>2011-10-25 13:54:56.000</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>115066</th>\n      <td>[록메탈, 밴드사운드, 록, 락메탈, 메탈, 락, extreme]</td>\n      <td>120325</td>\n      <td>METAL E'SM #2</td>\n      <td>[429629, 441511, 612106, 516359, 691768, 38714...</td>\n      <td>3</td>\n      <td>2020-04-17 04:31:11.000</td>\n    </tr>\n    <tr>\n      <th>115067</th>\n      <td>[일렉]</td>\n      <td>106976</td>\n      <td>빠른 리스너를 위한 따끈따끈한 최신 인기 EDM 모음!</td>\n      <td>[321330, 216057, 534472, 240306, 331098, 23288...</td>\n      <td>13</td>\n      <td>2015-12-24 17:23:19.000</td>\n    </tr>\n    <tr>\n      <th>115068</th>\n      <td>[담시, 가족, 눈물, 그리움, 주인공, 나의_이야기, 사랑, 친구]</td>\n      <td>11343</td>\n      <td>#1. 눈물이 앞을 가리는 나의_이야기</td>\n      <td>[50512, 249024, 250608, 371171, 229942, 694943...</td>\n      <td>4</td>\n      <td>2019-08-16 20:59:22.000</td>\n    </tr>\n    <tr>\n      <th>115069</th>\n      <td>[잔잔한, 버스, 퇴근버스, Pop, 풍경, 퇴근길]</td>\n      <td>131982</td>\n      <td>퇴근 버스에서 편히 들으면서 하루를 마무리하기에 좋은 POP</td>\n      <td>[533534, 608114, 343608, 417140, 609009, 30217...</td>\n      <td>4</td>\n      <td>2019-10-25 23:40:42.000</td>\n    </tr>\n    <tr>\n      <th>115070</th>\n      <td>[노래추천, 팝송추천, 팝송, 팝송모음]</td>\n      <td>100389</td>\n      <td>FAVORITE POPSONG!!!</td>\n      <td>[26008, 456354, 324105, 89871, 135272, 143548,...</td>\n      <td>17</td>\n      <td>2020-04-18 20:35:06.000</td>\n    </tr>\n  </tbody>\n</table>\n<p>115071 rows × 6 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs = [__ for _ in train.songs for __ in _]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "615142"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "len(set(songs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 노래가 100번 초과인 곡들만 선택\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false,
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "song_selected = [_[0] for _ in list(filter(lambda e: e[1] > 100, Counter(songs).items()))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "8491\n"
    }
   ],
   "source": [
    "n = len(song_selected)\n",
    "print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"song_selected\"] = train.songs.apply(lambda e: [_ for _ in e if _ in song_selected])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "99266\n"
    }
   ],
   "source": [
    "train_w_selected_song = train[train.song_selected.apply(lambda e: bool(e))]\n",
    "print(len(train_w_selected_song)) # 플레이리스트중 100번 초과 곡이 list에 들어있는 플레이리스트 수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 정연님이 구현하신 embedding (훨씬 빠르고 간단, sklearn의 OneHotEncoder 사용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([0., 0., 0., ..., 0., 0., 0.])"
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder()\n",
    "enc.fit(np.array(song_selected).reshape(-1, 1))\n",
    "enc.transform(np.array([497066, 389529]).reshape(-1, 1)).toarray().sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(train):\n",
    "    X = np.array([enc.transform(np.array(song_list).reshape(-1,1)).toarray().sum(axis=0) for song_list in train.song_selected])\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = one_hot(train_w_selected_song)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(79412, 8491) (19854, 8491)\n"
    }
   ],
   "source": [
    "x_train = X[:int(X.shape[0]*0.8)]\n",
    "x_test = X[int(X.shape[0]*0.8):]\n",
    "print(x_train.shape, x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "<keras.layers.core.Dense object at 0x7fb971aad4d0>\n<keras.layers.core.Dense object at 0x7fb971aad4d0>\n"
    }
   ],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "\n",
    "# configure\n",
    "encoding_dim = 150\n",
    "input_song = Input(shape=(n,))\n",
    "\n",
    "# layers\n",
    "encoded = Dense(encoding_dim, activation='relu')(input_song)\n",
    "decoded = Dense(n, activation='sigmoid')(encoded)\n",
    "\n",
    "# Models\n",
    "autoencoder = Model(input_song, decoded) # autoencoder\n",
    "encoder = Model(input_song, encoded) # encoder\n",
    "encoded_input = Input(shape=(encoding_dim,))\n",
    "decoder_layer = autoencoder.layers[-1]\n",
    "decoder = Model(encoded_input, decoder_layer(encoded_input)) # decoder\n",
    "\n",
    "print(autoencoder.layers[-2])\n",
    "print(encoder.layers[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Train on 79412 samples, validate on 19854 samples\nEpoch 1/50\n 7776/79412 [=>............................] - ETA: 42s - loss: 0.6838 - rmse: 0.4953 - recall: 0.1655"
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-9918c7d73feb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     38\u001b[0m                 \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m                 \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m                 validation_data=(x_test, x_test))\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;31m# encoding result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data1/home/hscho100/anaconda3/envs/long8v/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[0;32m/data1/home/hscho100/anaconda3/envs/long8v/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    184\u001b[0m                             fit_inputs[:-1], batch_ids) + [fit_inputs[-1]]\n\u001b[1;32m    185\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m                         \u001b[0mins_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslice_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfit_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m                     raise TypeError('TypeError while preparing batch. '\n",
      "\u001b[0;32m/data1/home/hscho100/anaconda3/envs/long8v/lib/python3.7/site-packages/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mslice_arrays\u001b[0;34m(arrays, start, stop)\u001b[0m\n\u001b[1;32m    553\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'shape'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m                 \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    556\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data1/home/hscho100/anaconda3/envs/long8v/lib/python3.7/site-packages/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    553\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'shape'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m                 \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    556\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# .from keras.datasets import mnist\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "\n",
    "# configure\n",
    "encoding_dim = 150\n",
    "input_song = Input(shape=(n,))\n",
    "\n",
    "# layers\n",
    "encoded = Dense(encoding_dim, activation='relu')(input_song)\n",
    "decoded = Dense(n, activation='sigmoid')(encoded)\n",
    "\n",
    "# Models\n",
    "autoencoder = Model(input_song, decoded) # autoencoder\n",
    "encoder = Model(input_song, encoded) # encoder\n",
    "encoded_input = Input(shape=(encoding_dim,))\n",
    "decoder_layer = autoencoder.layers[-1]\n",
    "decoder = Model(encoded_input, decoder_layer(encoded_input)) # decoder\n",
    "\n",
    "# result viewer\n",
    "def rmse(y_true, y_pred):\n",
    "    return K.sqrt(K.mean(K.square(y_pred - y_true), axis=-1))\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    y_true_yn = K.round(K.clip(y_true, 0, 1))\n",
    "    y_pred_yn = K.round(K.clip(y_pred, 0, 1))\n",
    "\n",
    "    count_true_positive = K.sum(y_true_yn * y_pred_yn)\n",
    "    count_true_positive_false_negative = K.sum(y_true_yn)\n",
    "    recall = count_true_positive / (count_true_positive_false_negative + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "# train autoencoder\n",
    "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy', metrics=[rmse, recall])\n",
    "autoencoder.fit(x_train, x_train,\n",
    "                epochs=50,\n",
    "                batch_size=16,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test, x_test))\n",
    "\n",
    "# encoding result\n",
    "encoded_imgs = encoder.predict(x_test)\n",
    "decoded_imgs = decoder.predict(encoded_imgs)\n",
    "\n",
    "# classification train data\n",
    "reducted_x_train = encoder.predict(x_train)\n",
    "reducted_x_test = encoder.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-1d8f64990874>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m__\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0m__\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mTN\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0m__\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0m__\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m             \u001b[0mFP\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m__\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0m__\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "predicted = decoded_imgs > 0.5\n",
    "accuracy = 0; precision = 0\n",
    "for _ in list(zip(x_test, predicted)):\n",
    "    \n",
    "    TP = 0 ; TN = 0; FP = 0; FN = 0\n",
    "    for __ in list(zip(_[0], _[1])):\n",
    "        if __[0] == 1 and  __[1] == 1:\n",
    "            TP += 1\n",
    "        if __[0] == 0 and __[1] == 0:\n",
    "            TN += 1\n",
    "        if __[0] == 0 and __[1] == 1:\n",
    "            FP += 1\n",
    "        if __[0] == 1 and __[0] == 0:\n",
    "            FN += 1 \n",
    "    accuracy += (TP + TN) / (TP + TN + FP + FN)\n",
    "    precision += TP / (TP + FP + 0.00001)\n",
    "    \n",
    "print('accuracy :{} recall :{}'.format(accuracy/len(x_test), precision/len(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(19854, 8491)"
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "source": [
    "decoded_imgs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6000개 training set 결과"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Train on 6792 samples, validate on 92474 samples\nEpoch 1/50\n6792/6792 [==============================] - 15s 2ms/step - loss: 0.6867 - rmse: 0.4968 - recall: 0.0962 - val_loss: 0.6796 - val_rmse: 0.4932 - val_recall: 0.0077\nEpoch 2/50\n6792/6792 [==============================] - 15s 2ms/step - loss: 0.6519 - rmse: 0.4788 - recall: 0.0047 - val_loss: 0.5724 - val_rmse: 0.4359 - val_recall: 2.6617e-07\nEpoch 3/50\n6792/6792 [==============================] - 15s 2ms/step - loss: 0.3138 - rmse: 0.2633 - recall: 0.0000e+00 - val_loss: 0.1110 - val_rmse: 0.1109 - val_recall: 0.0000e+00\nEpoch 4/50\n6792/6792 [==============================] - 17s 2ms/step - loss: 0.0639 - rmse: 0.0730 - recall: 0.0000e+00 - val_loss: 0.0403 - val_rmse: 0.0553 - val_recall: 0.0000e+00\nEpoch 5/50\n6792/6792 [==============================] - 15s 2ms/step - loss: 0.0326 - rmse: 0.0503 - recall: 0.0000e+00 - val_loss: 0.0278 - val_rmse: 0.0475 - val_recall: 0.0000e+00\nEpoch 6/50\n6792/6792 [==============================] - 17s 3ms/step - loss: 0.0252 - rmse: 0.0462 - recall: 0.0000e+00 - val_loss: 0.0235 - val_rmse: 0.0455 - val_recall: 0.0000e+00\nEpoch 7/50\n6792/6792 [==============================] - 15s 2ms/step - loss: 0.0223 - rmse: 0.0449 - recall: 0.0000e+00 - val_loss: 0.0216 - val_rmse: 0.0447 - val_recall: 0.0000e+00\nEpoch 8/50\n6792/6792 [==============================] - 15s 2ms/step - loss: 0.0209 - rmse: 0.0443 - recall: 0.0000e+00 - val_loss: 0.0206 - val_rmse: 0.0443 - val_recall: 0.0000e+00\nEpoch 9/50\n6792/6792 [==============================] - 17s 3ms/step - loss: 0.0201 - rmse: 0.0441 - recall: 0.0000e+00 - val_loss: 0.0200 - val_rmse: 0.0441 - val_recall: 0.0000e+00\nEpoch 10/50\n6792/6792 [==============================] - 15s 2ms/step - loss: 0.0196 - rmse: 0.0439 - recall: 0.0000e+00 - val_loss: 0.0196 - val_rmse: 0.0440 - val_recall: 0.0000e+00\nEpoch 11/50\n6792/6792 [==============================] - 15s 2ms/step - loss: 0.0193 - rmse: 0.0438 - recall: 0.0000e+00 - val_loss: 0.0193 - val_rmse: 0.0439 - val_recall: 0.0000e+00\nEpoch 12/50\n6792/6792 [==============================] - 15s 2ms/step - loss: 0.0190 - rmse: 0.0438 - recall: 0.0000e+00 - val_loss: 0.0191 - val_rmse: 0.0439 - val_recall: 0.0000e+00\nEpoch 13/50\n6792/6792 [==============================] - 15s 2ms/step - loss: 0.0188 - rmse: 0.0437 - recall: 0.0000e+00 - val_loss: 0.0189 - val_rmse: 0.0438 - val_recall: 0.0000e+00\nEpoch 14/50\n6792/6792 [==============================] - 15s 2ms/step - loss: 0.0187 - rmse: 0.0437 - recall: 0.0000e+00 - val_loss: 0.0188 - val_rmse: 0.0438 - val_recall: 0.0000e+00\nEpoch 15/50\n6792/6792 [==============================] - 15s 2ms/step - loss: 0.0185 - rmse: 0.0437 - recall: 0.0000e+00 - val_loss: 0.0187 - val_rmse: 0.0438 - val_recall: 0.0000e+00\nEpoch 16/50\n6792/6792 [==============================] - 15s 2ms/step - loss: 0.0184 - rmse: 0.0437 - recall: 0.0000e+00 - val_loss: 0.0186 - val_rmse: 0.0438 - val_recall: 0.0000e+00\nEpoch 17/50\n6792/6792 [==============================] - 17s 2ms/step - loss: 0.0183 - rmse: 0.0436 - recall: 0.0000e+00 - val_loss: 0.0185 - val_rmse: 0.0437 - val_recall: 0.0000e+00\nEpoch 18/50\n6792/6792 [==============================] - 15s 2ms/step - loss: 0.0182 - rmse: 0.0436 - recall: 0.0000e+00 - val_loss: 0.0184 - val_rmse: 0.0437 - val_recall: 0.0000e+00\nEpoch 19/50\n6792/6792 [==============================] - 15s 2ms/step - loss: 0.0182 - rmse: 0.0436 - recall: 0.0000e+00 - val_loss: 0.0183 - val_rmse: 0.0437 - val_recall: 0.0000e+00\nEpoch 20/50\n6792/6792 [==============================] - 15s 2ms/step - loss: 0.0181 - rmse: 0.0436 - recall: 0.0000e+00 - val_loss: 0.0183 - val_rmse: 0.0437 - val_recall: 0.0000e+00\nEpoch 21/50\n6792/6792 [==============================] - 15s 2ms/step - loss: 0.0180 - rmse: 0.0436 - recall: 0.0000e+00 - val_loss: 0.0182 - val_rmse: 0.0437 - val_recall: 0.0000e+00\nEpoch 22/50\n6792/6792 [==============================] - 15s 2ms/step - loss: 0.0180 - rmse: 0.0436 - recall: 0.0000e+00 - val_loss: 0.0182 - val_rmse: 0.0437 - val_recall: 0.0000e+00\nEpoch 23/50\n6792/6792 [==============================] - 17s 2ms/step - loss: 0.0179 - rmse: 0.0436 - recall: 0.0000e+00 - val_loss: 0.0181 - val_rmse: 0.0437 - val_recall: 0.0000e+00\nEpoch 24/50\n6792/6792 [==============================] - 15s 2ms/step - loss: 0.0178 - rmse: 0.0436 - recall: 0.0000e+00 - val_loss: 0.0180 - val_rmse: 0.0437 - val_recall: 0.0000e+00\nEpoch 25/50\n6792/6792 [==============================] - 15s 2ms/step - loss: 0.0178 - rmse: 0.0436 - recall: 0.0000e+00 - val_loss: 0.0180 - val_rmse: 0.0437 - val_recall: 0.0000e+00\nEpoch 26/50\n6792/6792 [==============================] - 15s 2ms/step - loss: 0.0177 - rmse: 0.0436 - recall: 0.0000e+00 - val_loss: 0.0179 - val_rmse: 0.0437 - val_recall: 0.0000e+00\nEpoch 27/50\n6792/6792 [==============================] - 15s 2ms/step - loss: 0.0177 - rmse: 0.0436 - recall: 0.0000e+00 - val_loss: 0.0179 - val_rmse: 0.0437 - val_recall: 0.0000e+00\nEpoch 28/50\n6792/6792 [==============================] - 17s 2ms/step - loss: 0.0176 - rmse: 0.0436 - recall: 0.0000e+00 - val_loss: 0.0179 - val_rmse: 0.0437 - val_recall: 0.0000e+00\nEpoch 29/50\n6792/6792 [==============================] - 15s 2ms/step - loss: 0.0176 - rmse: 0.0436 - recall: 0.0000e+00 - val_loss: 0.0178 - val_rmse: 0.0437 - val_recall: 0.0000e+00\nEpoch 30/50\n6792/6792 [==============================] - 15s 2ms/step - loss: 0.0175 - rmse: 0.0436 - recall: 0.0000e+00 - val_loss: 0.0178 - val_rmse: 0.0437 - val_recall: 0.0000e+00\nEpoch 31/50\n6792/6792 [==============================] - 15s 2ms/step - loss: 0.0175 - rmse: 0.0436 - recall: 0.0000e+00 - val_loss: 0.0177 - val_rmse: 0.0437 - val_recall: 0.0000e+00\nEpoch 32/50\n6792/6792 [==============================] - 15s 2ms/step - loss: 0.0174 - rmse: 0.0435 - recall: 0.0000e+00 - val_loss: 0.0177 - val_rmse: 0.0437 - val_recall: 0.0000e+00\nEpoch 33/50\n6792/6792 [==============================] - 15s 2ms/step - loss: 0.0174 - rmse: 0.0435 - recall: 0.0000e+00 - val_loss: 0.0176 - val_rmse: 0.0437 - val_recall: 0.0000e+00\nEpoch 34/50\n6792/6792 [==============================] - 15s 2ms/step - loss: 0.0174 - rmse: 0.0435 - recall: 0.0000e+00 - val_loss: 0.0176 - val_rmse: 0.0436 - val_recall: 0.0000e+00\nEpoch 35/50\n6792/6792 [==============================] - 15s 2ms/step - loss: 0.0173 - rmse: 0.0435 - recall: 0.0000e+00 - val_loss: 0.0176 - val_rmse: 0.0436 - val_recall: 0.0000e+00\nEpoch 36/50\n6792/6792 [==============================] - 17s 2ms/step - loss: 0.0173 - rmse: 0.0435 - recall: 0.0000e+00 - val_loss: 0.0175 - val_rmse: 0.0436 - val_recall: 0.0000e+00\nEpoch 37/50\n6792/6792 [==============================] - 15s 2ms/step - loss: 0.0172 - rmse: 0.0435 - recall: 0.0000e+00 - val_loss: 0.0175 - val_rmse: 0.0436 - val_recall: 0.0000e+00\nEpoch 38/50\n6792/6792 [==============================] - 15s 2ms/step - loss: 0.0172 - rmse: 0.0435 - recall: 0.0000e+00 - val_loss: 0.0175 - val_rmse: 0.0436 - val_recall: 0.0000e+00\nEpoch 39/50\n6792/6792 [==============================] - 15s 2ms/step - loss: 0.0172 - rmse: 0.0435 - recall: 0.0000e+00 - val_loss: 0.0174 - val_rmse: 0.0436 - val_recall: 0.0000e+00\nEpoch 40/50\n6792/6792 [==============================] - 15s 2ms/step - loss: 0.0171 - rmse: 0.0435 - recall: 0.0000e+00 - val_loss: 0.0174 - val_rmse: 0.0436 - val_recall: 0.0000e+00\nEpoch 41/50\n6792/6792 [==============================] - 15s 2ms/step - loss: 0.0171 - rmse: 0.0435 - recall: 0.0000e+00 - val_loss: 0.0174 - val_rmse: 0.0436 - val_recall: 0.0000e+00\nEpoch 42/50\n6792/6792 [==============================] - 15s 2ms/step - loss: 0.0171 - rmse: 0.0435 - recall: 0.0000e+00 - val_loss: 0.0173 - val_rmse: 0.0436 - val_recall: 0.0000e+00\nEpoch 43/50\n6792/6792 [==============================] - 15s 2ms/step - loss: 0.0170 - rmse: 0.0435 - recall: 0.0000e+00 - val_loss: 0.0173 - val_rmse: 0.0436 - val_recall: 0.0000e+00\nEpoch 44/50\n6792/6792 [==============================] - 15s 2ms/step - loss: 0.0170 - rmse: 0.0435 - recall: 0.0000e+00 - val_loss: 0.0173 - val_rmse: 0.0436 - val_recall: 0.0000e+00\nEpoch 45/50\n6792/6792 [==============================] - 17s 2ms/step - loss: 0.0170 - rmse: 0.0435 - recall: 0.0000e+00 - val_loss: 0.0172 - val_rmse: 0.0436 - val_recall: 0.0000e+00\nEpoch 46/50\n6792/6792 [==============================] - 15s 2ms/step - loss: 0.0169 - rmse: 0.0435 - recall: 0.0000e+00 - val_loss: 0.0172 - val_rmse: 0.0436 - val_recall: 0.0000e+00\nEpoch 47/50\n6792/6792 [==============================] - 15s 2ms/step - loss: 0.0169 - rmse: 0.0435 - recall: 0.0000e+00 - val_loss: 0.0172 - val_rmse: 0.0436 - val_recall: 0.0000e+00\nEpoch 48/50\n6792/6792 [==============================] - 15s 2ms/step - loss: 0.0169 - rmse: 0.0435 - recall: 0.0000e+00 - val_loss: 0.0172 - val_rmse: 0.0436 - val_recall: 0.0000e+00\nEpoch 49/50\n6792/6792 [==============================] - 15s 2ms/step - loss: 0.0169 - rmse: 0.0435 - recall: 0.0000e+00 - val_loss: 0.0171 - val_rmse: 0.0436 - val_recall: 0.0000e+00\nEpoch 50/50\n6792/6792 [==============================] - 15s 2ms/step - loss: 0.0168 - rmse: 0.0435 - recall: 0.0000e+00 - val_loss: 0.0171 - val_rmse: 0.0436 - val_recall: 0.0000e+00\n"
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "\n",
    "# configure\n",
    "encoding_dim = 32\n",
    "input_img = Input(shape=(n,))\n",
    "\n",
    "# layers\n",
    "encoded = Dense(encoding_dim, activation='relu')(input_img)\n",
    "decoded = Dense(n, activation='sigmoid')(encoded)\n",
    "\n",
    "# Models\n",
    "autoencoder = Model(input_img, decoded) # autoencoder\n",
    "encoder = Model(input_img, encoded) # encoder\n",
    "encoded_input = Input(shape=(encoding_dim,))\n",
    "decoder_layer = autoencoder.layers[-1]\n",
    "decoder = Model(encoded_input, decoder_layer(encoded_input)) # decoder\n",
    "\n",
    "# result viewer\n",
    "def rmse(y_true, y_pred):\n",
    "    return K.sqrt(K.mean(K.square(y_pred - y_true), axis=-1))\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    y_true_yn = K.round(K.clip(y_true, 0, 1))\n",
    "    y_pred_yn = K.round(K.clip(y_pred, 0, 1))\n",
    "\n",
    "    count_true_positive = K.sum(y_true_yn * y_pred_yn)\n",
    "    count_true_positive_false_negative = K.sum(y_true_yn)\n",
    "    recall = count_true_positive / (count_true_positive_false_negative + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "# train autoencoder\n",
    "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy', metrics=[rmse, recall])\n",
    "autoencoder.fit(x_train, x_train,\n",
    "                epochs=50,\n",
    "                batch_size=16,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test, x_test))\n",
    "\n",
    "# encoding result\n",
    "encoded_imgs = encoder.predict(x_test)\n",
    "decoded_imgs = decoder.predict(encoded_imgs)\n",
    "\n",
    "# classification train data\n",
    "reducted_x_train = encoder.predict(x_train)\n",
    "reducted_x_test = encoder.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "accuracy :0.05438047712800866 recall :0.002953596569696424\n"
    }
   ],
   "source": [
    "predicted = reducted_x_test > 0.5\n",
    "accuracy = 0; precision = 0\n",
    "for _ in list(zip(x_test, predicted)):\n",
    "    \n",
    "    TP = 0 ; TN = 0; FP = 0; FN = 0\n",
    "    for __ in list(zip(_[0], _[1])):\n",
    "        if __[0] == 1 and  __[1] == 1:\n",
    "            TP += 1\n",
    "        if __[0] == 0 and __[1] == 0:\n",
    "            TN += 1\n",
    "        if __[0] == 0 and __[1] == 1:\n",
    "            FP += 1\n",
    "        if __[0] == 1 and __[0] == 0:\n",
    "            FN += 1 \n",
    "    accuracy += (TP + TN) / (TP + TN + FP + FN)\n",
    "    precision += TP / (TP + FP)\n",
    "    \n",
    "print('accuracy :{} recall :{}'.format(accuracy/len(x_test), precision/len(x_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## =============================================\n",
    "###           최초에 짠 코드 폐기 예정\n",
    "## ============================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.zeros(n)\n",
    "for _ in train_1.song_selected_idx:\n",
    "    temp = np.zeros(n)\n",
    "    temp[_] = 1\n",
    "    X = np.vstack((X, temp))\n",
    "\n",
    "X = X[1:]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit ('long8v': conda)",
   "language": "python",
   "name": "python37764bitlong8vconda7e2246434fad429885f87bd19facd082"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
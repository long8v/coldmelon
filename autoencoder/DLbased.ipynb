{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from collections import Counter\n",
    "import torch\n",
    "from util.arena_util import load_json\n",
    "from util.arena_util import write_json\n",
    "import json\n",
    "# PyTorch imports\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from models import *\n",
    "torch.manual_seed(0)\n",
    "# Workspace imports\n",
    "#from evaluate import evaluate_model\n",
    "#from utils import train_one_epoch, test, plot_statistics\n",
    "\n",
    "# Python imports\n",
    "import argparse\n",
    "from time import time\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _split_data(playlists):\n",
    "    tot = len(playlists)\n",
    "    train = playlists[:int(tot*0.80)]\n",
    "    val = playlists[int(tot*0.80):]\n",
    "\n",
    "    return train, val\n",
    "def _mask(playlists, mask_cols, del_cols):\n",
    "    q_pl = copy.deepcopy(playlists)\n",
    "    a_pl = copy.deepcopy(playlists)\n",
    "\n",
    "    for i in range(len(playlists)):\n",
    "        for del_col in del_cols:\n",
    "            q_pl[i][del_col] = []\n",
    "            if del_col == 'songs':\n",
    "                a_pl[i][del_col] = a_pl[i][del_col][:100]\n",
    "            elif del_col == 'tags':\n",
    "                a_pl[i][del_col] = a_pl[i][del_col][:10]\n",
    "\n",
    "        for col in mask_cols:\n",
    "            mask_len = len(playlists[i][col])\n",
    "            mask = np.full(mask_len, False)\n",
    "            mask[:mask_len//2] = True\n",
    "            np.random.shuffle(mask)\n",
    "\n",
    "            q_pl[i][col] = list(np.array(q_pl[i][col])[mask])\n",
    "            a_pl[i][col] = list(np.array(a_pl[i][col])[np.invert(mask)])\n",
    "\n",
    "    return q_pl, a_pl\n",
    "\n",
    "def _mask_data(playlists):\n",
    "    playlists = copy.deepcopy(playlists)\n",
    "    tot = len(playlists)\n",
    "    song_only = playlists[:int(tot * 0.3)]\n",
    "    song_and_tags = playlists[int(tot * 0.3):int(tot * 0.8)]\n",
    "    tags_only = playlists[int(tot * 0.8):int(tot * 0.95)]\n",
    "    title_only = playlists[int(tot * 0.95):]\n",
    "\n",
    "    print(f\"Total: {len(playlists)}, \"\n",
    "            f\"Song only: {len(song_only)}, \"\n",
    "            f\"Song & Tags: {len(song_and_tags)}, \"\n",
    "            f\"Tags only: {len(tags_only)}, \"\n",
    "            f\"Title only: {len(title_only)}\")\n",
    "\n",
    "    song_q, song_a = _mask(song_only, ['songs'], ['tags'])\n",
    "    songtag_q, songtag_a = _mask(song_and_tags, ['songs', 'tags'], [])\n",
    "    tag_q, tag_a = _mask(tags_only, ['tags'], ['songs'])\n",
    "    title_q, title_a = _mask(title_only, [], ['songs', 'tags'])\n",
    "\n",
    "    q = song_q + songtag_q + tag_q + title_q\n",
    "    a = song_a + songtag_a + tag_a + title_a\n",
    "\n",
    "    shuffle_indices = np.arange(len(q))\n",
    "    np.random.shuffle(shuffle_indices)\n",
    "\n",
    "    q = list(np.array(q)[shuffle_indices])\n",
    "    a = list(np.array(a)[shuffle_indices])\n",
    "\n",
    "    return q, a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##train = pd.read_json('../file/train.json', encoding='utf-8')\n",
    "#song_meta = pd.read_json('../file/song_meta.json', encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Reading data...\n\nTotal playlists: 115071\nSplitting data...\n"
    }
   ],
   "source": [
    "random.seed(777)\n",
    "fname = '../file/train.json'\n",
    "print(\"Reading data...\\n\")\n",
    "playlists = load_json(fname)\n",
    "random.shuffle(playlists)\n",
    "print(f\"Total playlists: {len(playlists)}\")\n",
    "\n",
    "print(\"Splitting data...\")\n",
    "train, val = _split_data(playlists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "92056 23015\n"
    }
   ],
   "source": [
    "print(len(train),len(val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Total: 115071, Song only: 34521, Song & Tags: 57535, Tags only: 17261, Title only: 5754\n115071 115071\n"
    }
   ],
   "source": [
    "train_q, train_a = _mask_data(playlists)\n",
    "print(len(train_q),len(train_a))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Masked...\n"
    }
   ],
   "source": [
    "print(\"Masked...\")\n",
    "write_json(train_q, \"train_q.json\")\n",
    "write_json(train_a, \"train_a.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "plylst = pd.read_json('../file/train.json', encoding='utf-8')\n",
    "plylst_train_q = pd.read_json('arena_data/train_q.json', encoding='utf-8')\n",
    "plylst_train_a = pd.read_json('arena_data/train_a.json', encoding='utf-8')\n",
    "#song_meta = pd.read_json('../file/song_meta.json', encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_q = load_json('arena_data/train_q.json')\n",
    "train_a = load_json('arena_data/train_a.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "plylst_tag = plylst['tags']\n",
    "tag_counter = Counter([tg for tgs in plylst_tag for tg in tgs])\n",
    "tag_dict = {x: tag_counter[x] for x in tag_counter}\n",
    "\n",
    "tag_id_tid = dict()\n",
    "tag_tid_id = dict()\n",
    "for i, t in enumerate(tag_dict):\n",
    "    tag_id_tid[t] = i\n",
    "    tag_tid_id[i] = t\n",
    "\n",
    "n_tags = len(tag_dict)\n",
    "\n",
    "plylst_song = plylst['songs']\n",
    "#song_selected = [_[0] for _ in list(filter(lambda e: e[1] > 100, Counter(songs).items()))]\n",
    "song_counter = Counter([sg for sgs in plylst_song for sg in sgs])\n",
    "song_dict = {x: song_counter[x] for x in song_counter}\n",
    "\n",
    "song_dict_100 = {x: song_counter[x] for x in song_counter if song_counter[x]>100}\n",
    "\n",
    "song_id_sid = dict()\n",
    "song_sid_id = dict()\n",
    "\n",
    "song_100_id_sid = dict()\n",
    "song_100_sid_id = dict()\n",
    "\n",
    "for i, t in enumerate(song_dict):\n",
    "    song_id_sid[t] = i\n",
    "    song_sid_id[i] = t\n",
    "\n",
    "for i, t in enumerate(song_dict_100):\n",
    "    song_100_id_sid[t] = i\n",
    "    song_100_sid_id[i] = t\n",
    "\n",
    "n_songs = len(song_dict)\n",
    "n_songs_100 = len(song_dict_100)\n",
    "n_plylst = len(plylst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "plylst['songs_id'] = plylst['songs'].map(lambda x: [song_100_id_sid.get(s) for s in x if song_100_id_sid.get(s) != None])\n",
    "plylst['tags_id'] = plylst['tags'].map(lambda x: [tag_id_tid.get(t) for t in x if tag_id_tid.get(t) != None])\n",
    "\n",
    "\n",
    "plylst_train_q['songs_id'] = plylst_train_q['songs'].map(lambda x: [song_100_id_sid.get(s) for s in x if song_100_id_sid.get(s) != None])\n",
    "plylst_train_q['tags_id'] = plylst_train_q['tags'].map(lambda x: [tag_id_tid.get(t) for t in x if tag_id_tid.get(t) != None])\n",
    "\n",
    "\n",
    "plylst_train_a['songs_id'] = plylst_train_a['songs'].map(lambda x: [song_100_id_sid.get(s) for s in x if song_100_id_sid.get(s) != None])\n",
    "plylst_train_a['tags_id'] = plylst_train_a['tags'].map(lambda x: [tag_id_tid.get(t) for t in x if tag_id_tid.get(t) != None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "115071\n"
    }
   ],
   "source": [
    "train_q_list = plylst_train_q['songs_id'].tolist()\n",
    "train_a_list = plylst_train_a['songs_id'].tolist()\n",
    "print(len(train_q_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "8491\n29160\n"
    }
   ],
   "source": [
    "print(n_songs_100)\n",
    "n_tags = len(tag_dict)\n",
    "print(n_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(train):\n",
    "    X = np.array([enc.transform(np.array(song_list).reshape(-1,1)).toarray().sum(axis=0) if song_list != [] else np.zeros(n_songs_100) for song_list in train.songs_id])\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_q = one_hot(plylst_train_q)\n",
    "X_a = one_hot(plylst_train_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(115071, 8491) (115071, 8491)\n"
    }
   ],
   "source": [
    "print(X_q.shape, X_a.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'\\n    args = parse_args()\\n    path = args.path\\n    dataset = args.dataset\\n    layers = eval(args.layers)\\n    weight_decay = args.weight_decay\\n    num_negatives_train = args.num_neg_train\\n    num_negatives_test = args.num_neg_test\\n    dropout = args.dropout\\n    learner = args.learner\\n    learning_rate = args.lr\\n    batch_size = args.batch_size\\n    epochs = args.epochs\\n    verbose = args.verbose\\n'"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "#from models import MLP\n",
    "model = MLP(n_tags, n_songs, layers=[1024, 256, 1024], dropout=False, use_cuda = True)\n",
    "'''\n",
    "    args = parse_args()\n",
    "    path = args.path\n",
    "    dataset = args.dataset\n",
    "    layers = eval(args.layers)\n",
    "    weight_decay = args.weight_decay\n",
    "    num_negatives_train = args.num_neg_train\n",
    "    num_negatives_test = args.num_neg_test\n",
    "    dropout = args.dropout\n",
    "    learner = args.learner\n",
    "    learning_rate = args.lr\n",
    "    batch_size = args.batch_size\n",
    "    epochs = args.epochs\n",
    "    verbose = args.verbose\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "optimizer = optim.Adam(model.parameters(), lr=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from training import Trainer\n",
    "trainer = Trainer(model, optimizer,\n",
    "                 print_loss_every=50,\n",
    "                 record_loss_every=5,\n",
    "                 use_cuda = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "# Dataset 상속\n",
    "class CustomDataset(Dataset): \n",
    "  def __init__(self, xinput, yinput, batchsize):\n",
    "    self.x_data = xinput\n",
    "    self.y_data = yinput\n",
    "    self.batch_size = batchsize\n",
    "\n",
    "  # 총 데이터의 개수를 리턴\n",
    "  def __len__(self): \n",
    "    return len(self.x_data)\n",
    "\n",
    "  # 인덱스를 입력받아 그에 맵핑되는 입출력 데이터를 파이토치의 Tensor 형태로 리턴\n",
    "  def __getitem__(self, idx): \n",
    "    x = torch.FloatTensor(self.x_data[idx])\n",
    "    y = torch.FloatTensor(self.y_data[idx])\n",
    "    return x, y\n",
    "\n",
    "mydata = CustomDataset(train_q_list, train_a_list, 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([]) tensor([5724., 2634., 1332.])\ntensor([ 959., 2739., 4066., 2748.]) tensor([6475., 2737., 1342., 2796., 2741., 2750.])\ntensor([1691.,  147.,  148., 1048., 1694.]) tensor([1362.,  149., 1693.,  150., 1049.])\ntensor([]) tensor([1455., 4941., 5575., 3786., 5576., 5577., 5357., 5358., 4243., 5201.,\n        5583., 3443., 1456., 3444., 6684., 6579., 3788.,  603.,  842., 1565.,\n        4889., 2123., 1881., 3342., 4062., 1336., 4069., 1956.,  877., 3689.,\n         278.,  292., 5350., 4516.,  384., 1963.,  437., 2252., 3350., 1446.,\n        1325.,  305., 2997., 4719.,  851., 4051., 1401., 6819., 5352., 4237.,\n        4040., 3384., 4036., 4728., 4240., 5580., 8464., 4068., 5581., 4033.,\n        4049., 3437., 4045., 4047., 4953., 4070., 3781., 5582., 3440., 2255.,\n        3441., 3442.,  981., 5572., 3759.])\ntensor([4.8450e+03, 1.4600e+03, 3.0000e+00, 4.1280e+03, 4.2990e+03, 1.4980e+03,\n        6.9990e+03, 2.7200e+02, 8.2260e+03, 6.5800e+03, 1.5640e+03, 1.2960e+03,\n        3.3750e+03, 1.2700e+03]) tensor([2176., 4924., 5527., 5724., 5819., 3320., 4922.,  482., 7083., 1499.,\n         619.,  846., 1526.])\n"
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    x,y=mydata[i]\n",
    "    print(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "Expected tensor for argument #1 'indices' to have scalar type Long; but got torch.FloatTensor instead (while checking arguments for embedding)",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-c02b5640c1ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmydata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/data1/home/hscho100/kakaoarena/coldmelon/autoencoder/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, data_loader, epochs, save_training_gif)\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0mepoch_train_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m             \u001b[0mmean_epoch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m             print('Epoch: {} Average loss: {:.2f} Training time: {:.2f}'.format(epoch + 1,\n\u001b[1;32m     71\u001b[0m                                                           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_pixels\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmean_epoch_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data1/home/hscho100/kakaoarena/coldmelon/autoencoder/training.py\u001b[0m in \u001b[0;36m_train_epoch\u001b[0;34m(self, data_loader)\u001b[0m\n\u001b[1;32m     84\u001b[0m                                \u001b[0;31m# self.print_loss_every\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m             \u001b[0miter_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m             \u001b[0mepoch_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0miter_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0mprint_every_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0miter_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data1/home/hscho100/kakaoarena/coldmelon/autoencoder/training.py\u001b[0m in \u001b[0;36m_train_iteration\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0mrecon_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatent_dist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_loss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecon_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatent_dist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data1/home/hscho100/anaconda3/envs/long8v/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data1/home/hscho100/kakaoarena/coldmelon/autoencoder/models.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, feed_dict)\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0msongs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0;31m# tag_embedding = self.tag_embedding(tags)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0msong_embedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msong_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msongs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0mtag_embedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtag_embedding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0msong_embedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msong_embedding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data1/home/hscho100/anaconda3/envs/long8v/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data1/home/hscho100/anaconda3/envs/long8v/lib/python3.7/site-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m         return F.embedding(\n\u001b[1;32m    113\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data1/home/hscho100/anaconda3/envs/long8v/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   1482\u001b[0m         \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1483\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1484\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1485\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected tensor for argument #1 'indices' to have scalar type Long; but got torch.FloatTensor instead (while checking arguments for embedding)"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(model, optimizer)\n",
    "trainer.train(mydata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLP(n_tags, n_songs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "# Build optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# full_dataset = CustomDataset(train_q, train_a)\n",
    "train_loader_q = DataLoader(train_q, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "train_loader_a = DataLoader(train_a, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "# .train(epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "torch.utils.data.dataloader.DataLoader"
     },
     "metadata": {},
     "execution_count": 102
    }
   ],
   "source": [
    "type(train_loader_q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# CUDA for PyTorch\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "# cudnn.benchmark = True\n",
    "\n",
    "\n",
    "def main():\n",
    "\n",
    "    args = parse_args()\n",
    "    path = args.path\n",
    "    dataset = args.dataset\n",
    "    layers = eval(args.layers)\n",
    "    weight_decay = args.weight_decay\n",
    "    num_negatives_train = args.num_neg_train\n",
    "    num_negatives_test = args.num_neg_test\n",
    "    dropout = args.dropout\n",
    "    learner = args.learner\n",
    "    learning_rate = args.lr\n",
    "    batch_size = args.batch_size\n",
    "    epochs = args.epochs\n",
    "    verbose = args.verbose\n",
    "\n",
    "    topK = 100\n",
    "    print(\"MLP arguments: %s \" % (args))\n",
    "    # model_out_file = 'Pretrain/%s_MLP_%s_%d.h5' %(args.dataset, args.layers, time())\n",
    "\n",
    "    # Load data\n",
    "\n",
    "    t1 = time()\n",
    "    full_dataset = CustomDataset(train_q_list, train_a_list)\n",
    "\n",
    "    train_data_q, train_data_a = full_dataset.x_data, full_dataset.y_data\n",
    "    num_data = len(full_dataset)\n",
    "\n",
    "    print(\"Load data done [%.1f s]. #user=%d, #item=%d\"\n",
    "          % (time()-t1, num_data, n_songs_100))\n",
    "    \n",
    "    #dataloader = DataLoader(dataset, batch_size=2, shuffle=True)\n",
    "    \n",
    "    training_data_generator = DataLoader(\n",
    "        full_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "\n",
    "    # Build model\n",
    "    model = MLP(num_data, n_songs_100, layers=layers, dropout=dropout)\n",
    "    # Transfer the model to GPU, if one is available\n",
    "    model.to(device)\n",
    "    if verbose:\n",
    "        print(model)\n",
    "\n",
    "    loss_fn = torch.nn.BCELoss()\n",
    "    # Use Adam optimizer\n",
    "    optimizer = torch.optim.Adam(model.parameters(), weight_decay=weight_decay)\n",
    "\n",
    "    # Record performance\n",
    "    hr_list = []\n",
    "    ndcg_list = []\n",
    "    BCE_loss_list = []\n",
    "\n",
    "    # Check Init performance\n",
    "    hr, ndcg = test(model, full_dataset, topK)\n",
    "    hr_list.append(hr)\n",
    "    ndcg_list.append(ndcg)\n",
    "    BCE_loss_list.append(1)\n",
    "    # do the epochs now\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss = train_one_epoch( model, training_data_generator, loss_fn, optimizer, epoch, device)\n",
    "\n",
    "        if epoch % verbose == 0:\n",
    "            hr, ndcg = test(model, full_dataset, topK)\n",
    "            hr_list.append(hr)\n",
    "            ndcg_list.append(ndcg)\n",
    "            BCE_loss_list.append(epoch_loss)\n",
    "            # if hr > best_hr:\n",
    "            #     best_hr, best_ndcg, best_iter = hr, ndcg, epoch\n",
    "            #     if args.out > 0:\n",
    "            #         model.save(model_out_file, overwrite=True)\n",
    "    print(\"hr for epochs: \", hr_list)\n",
    "    print(\"ndcg for epochs: \", ndcg_list)\n",
    "    print(\"loss for epochs: \", BCE_loss_list)\n",
    "    # plot_statistics(hr_list, ndcg_list, BCE_loss_list,model.get_alias(), \"./figs\")\n",
    "    # with open(\"metrics\", 'wb') as fp:\n",
    "    #     pickle.dump(hr_list, fp)\n",
    "    #     pickle.dump(ndcg_list, fp)\n",
    "\n",
    "    best_iter = np.argmax(np.array(hr_list))\n",
    "    best_hr = hr_list[best_iter]\n",
    "    best_ndcg = ndcg_list[best_iter]\n",
    "    print(\"End. Best Iteration %d:  HR = %.4f, NDCG = %.4f. \" %\n",
    "          (best_iter, best_hr, best_ndcg))\n",
    "    # if args.out > 0:\n",
    "    #     print(\"The best MLP model is saved to %s\" %(model_out_file))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Device available: {}\".format(device))\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37764bitlong8vconda7e2246434fad429885f87bd19facd082",
   "display_name": "Python 3.7.7 64-bit ('long8v': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
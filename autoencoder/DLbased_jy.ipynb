{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from collections import Counter\n",
    "import torch\n",
    "from util.arena_util import load_json\n",
    "from util.arena_util import write_json\n",
    "import json\n",
    "# PyTorch imports\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from models import *\n",
    "from training import Trainer\n",
    "\n",
    "torch.manual_seed(0)\n",
    "# Workspace imports\n",
    "#from evaluate import evaluate_model\n",
    "#from utils import train_one_epoch, test, plot_statistics\n",
    "\n",
    "# Python imports\n",
    "import argparse\n",
    "from time import time\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _split_data(playlists):\n",
    "    tot = len(playlists)\n",
    "    train = playlists[:int(tot*0.80)]\n",
    "    val = playlists[int(tot*0.80):]\n",
    "\n",
    "    return train, val\n",
    "def _mask(playlists, mask_cols, del_cols):\n",
    "    q_pl = copy.deepcopy(playlists)\n",
    "    a_pl = copy.deepcopy(playlists)\n",
    "\n",
    "    for i in range(len(playlists)):\n",
    "        for del_col in del_cols:\n",
    "            q_pl[i][del_col] = []\n",
    "            if del_col == 'songs':\n",
    "                a_pl[i][del_col] = a_pl[i][del_col][:100]\n",
    "            elif del_col == 'tags':\n",
    "                a_pl[i][del_col] = a_pl[i][del_col][:10]\n",
    "\n",
    "        for col in mask_cols:\n",
    "            mask_len = len(playlists[i][col])\n",
    "            mask = np.full(mask_len, False)\n",
    "            mask[:mask_len//2] = True\n",
    "            np.random.shuffle(mask)\n",
    "\n",
    "            q_pl[i][col] = list(np.array(q_pl[i][col])[mask])\n",
    "            a_pl[i][col] = list(np.array(a_pl[i][col])[np.invert(mask)])\n",
    "\n",
    "    return q_pl, a_pl\n",
    "\n",
    "def _mask_data(playlists):\n",
    "    playlists = copy.deepcopy(playlists)\n",
    "    tot = len(playlists)\n",
    "    # song_only = playlists[:int(tot * 0.3)]\n",
    "    # song_and_tags = playlists[int(tot * 0.3):int(tot * 0.8)]\n",
    "    # tags_only = playlists[int(tot * 0.8):int(tot * 0.95)]\n",
    "    # title_only = playlists[int(tot * 0.95):]\n",
    "    song_only = playlists[:int(tot * 0.4)]\n",
    "    song_and_tags = playlists[int(tot * 0.4):]\n",
    "\n",
    "    # print(f\"Total: {len(playlists)}, \"\n",
    "    #         f\"Song only: {len(song_only)}, \"\n",
    "    #         f\"Song & Tags: {len(song_and_tags)}, \"\n",
    "    #         f\"Tags only: {len(tags_only)}, \"\n",
    "    #         f\"Title only: {len(title_only)}\")\n",
    "\n",
    "    print(f\"Total: {len(playlists)}, \"\n",
    "            f\"Song only: {len(song_only)}, \"\n",
    "            f\"Song & Tags: {len(song_and_tags)}\"\n",
    "            )\n",
    "\n",
    "    song_q, song_a = _mask(song_only, ['songs'], ['tags'])\n",
    "    songtag_q, songtag_a = _mask(song_and_tags, ['songs', 'tags'], [])\n",
    "    # tag_q, tag_a = _mask(tags_only, ['tags'], ['songs'])\n",
    "    # title_q, title_a = _mask(title_only, [], ['songs', 'tags'])\n",
    "\n",
    "    q = song_q + songtag_q #+ tag_q + title_q\n",
    "    a = song_a + songtag_a #+ tag_a + title_a\n",
    "\n",
    "    shuffle_indices = np.arange(len(q))\n",
    "    np.random.shuffle(shuffle_indices)\n",
    "\n",
    "    q = list(np.array(q)[shuffle_indices])\n",
    "    a = list(np.array(a)[shuffle_indices])\n",
    "\n",
    "    return q, a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "##train = pd.read_json('../file/train.json', encoding='utf-8')\n",
    "#song_meta = pd.read_json('../file/song_meta.json', encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data...\n",
      "\n",
      "Total playlists: 115071\n"
     ]
    }
   ],
   "source": [
    "random.seed(777)\n",
    "fname = '../file/train.json'\n",
    "print(\"Reading data...\\n\")\n",
    "playlists = load_json(fname)\n",
    "random.shuffle(playlists)\n",
    "print(f\"Total playlists: {len(playlists)}\")\n",
    "\n",
    "# print(\"Splitting data...\")\n",
    "# train, val = _split_data(playlists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 115071, Song only: 46028, Song & Tags: 69043\n",
      "115071 115071\n"
     ]
    }
   ],
   "source": [
    "train_q, train_a = _mask_data(playlists)\n",
    "print(len(train_q),len(train_a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_q_ = train_q[:1000]\n",
    "train_a_ = train_a[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Masked...\n"
     ]
    }
   ],
   "source": [
    "print(\"Masked...\")\n",
    "write_json(train_q, \"train_q_new.json\")\n",
    "write_json(train_a, \"train_a_new.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = [trn['plylst_title'] for trn in train_q_]\n",
    "tags = [trn['tags'] for trn in train_q_]\n",
    "songs = [list(map(str, trn['songs'])) for trn in train_q_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mecab import Tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_pos = list(map(lambda e: list(zip(*Tagger().parse(e)))[0], title))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "pttn = re.compile('[~!@#$%^&*_■♪:.,/?!]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_tokenizer(sen):\n",
    "    try:\n",
    "        sen_pos = list(map(lambda e: list(zip(*Tagger().parse(e)))[0], sen))\n",
    "        sen_pos = [list(filter(lambda e: len(pttn.sub('',e))>1, t)) for t in sen_pos]\n",
    "        return sen_pos\n",
    "    except IndexError:\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_pos = [list(filter(lambda e: len(pttn.sub('',e))>1, t)) for t in title_pos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs = [list(map(str, song)) for song in songs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_songs = get_most_common(songs, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_most_common(nested_list, n_most):\n",
    "    common = Counter([__ for _ in nested_list for __ in _])\n",
    "    return list(map(str, list(zip(*common.most_common(n_most)))[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_selected_list(nested_list, use_set):\n",
    "    return [list(filter(lambda e: e in use_set, _)) for _ in nested_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dict(use_set):\n",
    "    idx_word = dict(enumerate(use_set))\n",
    "    word_idx = {value:str(key) for key, value in idx_word.items()}\n",
    "    return word_idx, idx_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_idx_list(nested_list, word_idx):\n",
    "    return [list(map(lambda e: word_idx[e], _)) for _ in nested_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(nested_list, n_most):\n",
    "    use_set = get_most_common(nested_list, n_most)\n",
    "    filtered_nested_list = get_selected_list(nested_list, use_set)\n",
    "    word_idx, idx_word = get_dict(use_set)\n",
    "    return get_idx_list(filtered_nested_list, word_idx), word_idx, idx_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs_, word_idx_song, idx_word_song = preprocess(songs, 1000)\n",
    "tags_, word_idx_tag, idx_word_tag = preprocess(tags, 100)\n",
    "titles_, word_idx_title, idx_word_title = preprocess(title_pos, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs_ = [s if s else [str(len(word_idx_song))] for s in songs_ ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_title = Word2Vec(titles_)\n",
    "w2v_tag = Word2Vec(tags_)\n",
    "w2v_song = Word2Vec(songs_, size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_q_ = pd.DataFrame(train_q_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_q_['pos_title'] = title_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_q_['song_idx'] = songs_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_q_['tags_idx'] = tags_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_q_['title_idx'] = titles_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tags</th>\n",
       "      <th>id</th>\n",
       "      <th>plylst_title</th>\n",
       "      <th>songs</th>\n",
       "      <th>like_cnt</th>\n",
       "      <th>updt_date</th>\n",
       "      <th>pos_title</th>\n",
       "      <th>song_idx</th>\n",
       "      <th>tags_idx</th>\n",
       "      <th>title_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[]</td>\n",
       "      <td>11043</td>\n",
       "      <td>결국 목소리다 – 시원하게 질러주는 성악 모음</td>\n",
       "      <td>[688032, 512889, 480493, 291722, 565605, 55572...</td>\n",
       "      <td>67</td>\n",
       "      <td>2018-07-30 22:48:50.000</td>\n",
       "      <td>[결국, 목소리, 시원, 질러, 성악, 모음]</td>\n",
       "      <td>[1000]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[72, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[주말, 여유, 사색을위한클래식, 아이를위한클래식, 분위기있는클래식]</td>\n",
       "      <td>62865</td>\n",
       "      <td>편안한 명상을 위한 릴랙스요가클래식</td>\n",
       "      <td>[623782, 172865, 186124, 652748, 495190, 37751...</td>\n",
       "      <td>376</td>\n",
       "      <td>2019-04-27 10:04:38.000</td>\n",
       "      <td>[편안, 명상, 위한, 랙스, 요가, 클래식]</td>\n",
       "      <td>[890, 891, 892, 893, 894, 895, 896, 897, 898, ...</td>\n",
       "      <td>[52, 66]</td>\n",
       "      <td>[82, 26, 35]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[]</td>\n",
       "      <td>14741</td>\n",
       "      <td>Super Brass, Jim &amp; Friends</td>\n",
       "      <td>[130052, 11689, 516656, 327877, 79841, 319524]</td>\n",
       "      <td>3</td>\n",
       "      <td>2013-04-29 14:16:23.000</td>\n",
       "      <td>[Super, Brass, Jim, Friends]</td>\n",
       "      <td>[1000]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[추억, 발라드]</td>\n",
       "      <td>65882</td>\n",
       "      <td>너와 이별했을때 듣던 노래 그리고 숨겨진 이야기</td>\n",
       "      <td>[651499, 593128, 555781, 651332, 153569, 44817...</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-04-03 13:32:58.000</td>\n",
       "      <td>[이별, 노래, 그리고, 숨겨진, 이야기]</td>\n",
       "      <td>[389, 18, 903, 390, 175, 904, 3, 905, 391, 392...</td>\n",
       "      <td>[9, 11]</td>\n",
       "      <td>[45, 0, 96]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[클래식, 성악, 바흐, 칸타타, 휴식힐링]</td>\n",
       "      <td>39812</td>\n",
       "      <td>바로크 시대에 성행한 악곡형식, 칸타타 대표 작품들</td>\n",
       "      <td>[684783, 480909, 688156, 239226, 557658, 67557...</td>\n",
       "      <td>624</td>\n",
       "      <td>2019-04-16 08:38:13.000</td>\n",
       "      <td>[바로크, 시대, 성행, 악곡, 형식, 칸타타, 대표, 작품]</td>\n",
       "      <td>[1000]</td>\n",
       "      <td>[39]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>[봄날]</td>\n",
       "      <td>100383</td>\n",
       "      <td>설레이는 봄에 설레임을 증폭 시켜 줄 플레이리스트 :)</td>\n",
       "      <td>[313262, 365394, 418192, 409519, 206812, 33239...</td>\n",
       "      <td>5</td>\n",
       "      <td>2017-04-12 11:41:38.000</td>\n",
       "      <td>[설레이, 설레임, 증폭, 시켜, 플레이, 리스트]</td>\n",
       "      <td>[889, 817, 871]</td>\n",
       "      <td>[79]</td>\n",
       "      <td>[20, 7]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>[기분좋은, 연휴, 카페, 펍, 편안한]</td>\n",
       "      <td>12638</td>\n",
       "      <td>늦은 저녁 카페 펍에서 듣는 리스트! 팝, 록, 알앤비 etc.</td>\n",
       "      <td>[135272, 304656, 169198, 49771, 358506, 479177...</td>\n",
       "      <td>243</td>\n",
       "      <td>2017-10-19 14:56:43.000</td>\n",
       "      <td>[저녁, 카페, 에서, 리스트, etc]</td>\n",
       "      <td>[1000]</td>\n",
       "      <td>[8]</td>\n",
       "      <td>[78, 16, 4, 7]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>[겨울, 휴식, 카페, 기분전환]</td>\n",
       "      <td>132103</td>\n",
       "      <td>잔잔한 Vibe!!! 좋은 분위기 히팝~!!</td>\n",
       "      <td>[325871, 652209, 282708, 347966, 662545, 18551...</td>\n",
       "      <td>9</td>\n",
       "      <td>2018-02-05 22:48:41.000</td>\n",
       "      <td>[잔잔, Vibe, 분위기]</td>\n",
       "      <td>[39, 811]</td>\n",
       "      <td>[31, 3, 8, 1]</td>\n",
       "      <td>[14, 13]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>[]</td>\n",
       "      <td>6200</td>\n",
       "      <td>봄에 듣기 좋은 노래</td>\n",
       "      <td>[455668, 122363, 549178, 407828, 343974, 8719,...</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-04-23 15:22:30.000</td>\n",
       "      <td>[노래]</td>\n",
       "      <td>[784, 7, 36, 0, 68, 19, 177, 70, 708]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>[명불허전OST, 사랑]</td>\n",
       "      <td>96176</td>\n",
       "      <td>서로의 마음을 확인한 순간, 키스신 OST</td>\n",
       "      <td>[132247, 203264, 352096, 129654, 405408, 32235...</td>\n",
       "      <td>400</td>\n",
       "      <td>2019-11-25 02:29:06.000</td>\n",
       "      <td>[서로, 마음, 확인, 순간, 키스, OST]</td>\n",
       "      <td>[71, 879, 887, 78]</td>\n",
       "      <td>[4]</td>\n",
       "      <td>[5, 67]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       tags      id  \\\n",
       "0                                        []   11043   \n",
       "1    [주말, 여유, 사색을위한클래식, 아이를위한클래식, 분위기있는클래식]   62865   \n",
       "2                                        []   14741   \n",
       "3                                 [추억, 발라드]   65882   \n",
       "4                  [클래식, 성악, 바흐, 칸타타, 휴식힐링]   39812   \n",
       "..                                      ...     ...   \n",
       "995                                    [봄날]  100383   \n",
       "996                  [기분좋은, 연휴, 카페, 펍, 편안한]   12638   \n",
       "997                      [겨울, 휴식, 카페, 기분전환]  132103   \n",
       "998                                      []    6200   \n",
       "999                           [명불허전OST, 사랑]   96176   \n",
       "\n",
       "                            plylst_title  \\\n",
       "0              결국 목소리다 – 시원하게 질러주는 성악 모음   \n",
       "1                    편안한 명상을 위한 릴랙스요가클래식   \n",
       "2             Super Brass, Jim & Friends   \n",
       "3             너와 이별했을때 듣던 노래 그리고 숨겨진 이야기   \n",
       "4           바로크 시대에 성행한 악곡형식, 칸타타 대표 작품들   \n",
       "..                                   ...   \n",
       "995       설레이는 봄에 설레임을 증폭 시켜 줄 플레이리스트 :)   \n",
       "996  늦은 저녁 카페 펍에서 듣는 리스트! 팝, 록, 알앤비 etc.   \n",
       "997             잔잔한 Vibe!!! 좋은 분위기 히팝~!!   \n",
       "998                          봄에 듣기 좋은 노래   \n",
       "999              서로의 마음을 확인한 순간, 키스신 OST   \n",
       "\n",
       "                                                 songs  like_cnt  \\\n",
       "0    [688032, 512889, 480493, 291722, 565605, 55572...        67   \n",
       "1    [623782, 172865, 186124, 652748, 495190, 37751...       376   \n",
       "2       [130052, 11689, 516656, 327877, 79841, 319524]         3   \n",
       "3    [651499, 593128, 555781, 651332, 153569, 44817...         0   \n",
       "4    [684783, 480909, 688156, 239226, 557658, 67557...       624   \n",
       "..                                                 ...       ...   \n",
       "995  [313262, 365394, 418192, 409519, 206812, 33239...         5   \n",
       "996  [135272, 304656, 169198, 49771, 358506, 479177...       243   \n",
       "997  [325871, 652209, 282708, 347966, 662545, 18551...         9   \n",
       "998  [455668, 122363, 549178, 407828, 343974, 8719,...         1   \n",
       "999  [132247, 203264, 352096, 129654, 405408, 32235...       400   \n",
       "\n",
       "                   updt_date                           pos_title  \\\n",
       "0    2018-07-30 22:48:50.000           [결국, 목소리, 시원, 질러, 성악, 모음]   \n",
       "1    2019-04-27 10:04:38.000           [편안, 명상, 위한, 랙스, 요가, 클래식]   \n",
       "2    2013-04-29 14:16:23.000        [Super, Brass, Jim, Friends]   \n",
       "3    2020-04-03 13:32:58.000             [이별, 노래, 그리고, 숨겨진, 이야기]   \n",
       "4    2019-04-16 08:38:13.000  [바로크, 시대, 성행, 악곡, 형식, 칸타타, 대표, 작품]   \n",
       "..                       ...                                 ...   \n",
       "995  2017-04-12 11:41:38.000        [설레이, 설레임, 증폭, 시켜, 플레이, 리스트]   \n",
       "996  2017-10-19 14:56:43.000              [저녁, 카페, 에서, 리스트, etc]   \n",
       "997  2018-02-05 22:48:41.000                     [잔잔, Vibe, 분위기]   \n",
       "998  2019-04-23 15:22:30.000                                [노래]   \n",
       "999  2019-11-25 02:29:06.000           [서로, 마음, 확인, 순간, 키스, OST]   \n",
       "\n",
       "                                              song_idx       tags_idx  \\\n",
       "0                                               [1000]             []   \n",
       "1    [890, 891, 892, 893, 894, 895, 896, 897, 898, ...       [52, 66]   \n",
       "2                                               [1000]             []   \n",
       "3    [389, 18, 903, 390, 175, 904, 3, 905, 391, 392...        [9, 11]   \n",
       "4                                               [1000]           [39]   \n",
       "..                                                 ...            ...   \n",
       "995                                    [889, 817, 871]           [79]   \n",
       "996                                             [1000]            [8]   \n",
       "997                                          [39, 811]  [31, 3, 8, 1]   \n",
       "998              [784, 7, 36, 0, 68, 19, 177, 70, 708]             []   \n",
       "999                                 [71, 879, 887, 78]            [4]   \n",
       "\n",
       "          title_idx  \n",
       "0           [72, 3]  \n",
       "1      [82, 26, 35]  \n",
       "2                []  \n",
       "3       [45, 0, 96]  \n",
       "4                []  \n",
       "..              ...  \n",
       "995         [20, 7]  \n",
       "996  [78, 16, 4, 7]  \n",
       "997        [14, 13]  \n",
       "998             [0]  \n",
       "999         [5, 67]  \n",
       "\n",
       "[1000 rows x 10 columns]"
      ]
     },
     "execution_count": 436,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_q_['songs_idx_embed'] = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trian_q_.pos_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tags': [], 'id': 11043, 'plylst_title': '결국 목소리다 – 시원하게 질러주는 성악 모음', 'songs': [688032, 512889, 480493, 291722, 565605, 555723, 680174, 13106, 301396, 145012, 595590, 198198, 80053, 268090, 23427], 'like_cnt': 67, 'updt_date': '2018-07-30 22:48:50.000'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jy927nam/anaconda3/envs/long36v/lib/python3.6/site-packages/ipykernel_launcher.py:9: DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "688032",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-370-7d57f6de9189>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m                         if _ in w2v_title])\n\u001b[1;32m     10\u001b[0m     song_vec = np.mean([[w2v_song.wv[word_idx_song[_]] \n\u001b[0;32m---> 11\u001b[0;31m                          for _ in songs_tr]])\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtag_vec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle_vec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msong_vec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-370-7d57f6de9189>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      9\u001b[0m                         if _ in w2v_title])\n\u001b[1;32m     10\u001b[0m     song_vec = np.mean([[w2v_song.wv[word_idx_song[_]] \n\u001b[0;32m---> 11\u001b[0;31m                          for _ in songs_tr]])\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtag_vec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle_vec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msong_vec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 688032"
     ]
    }
   ],
   "source": [
    "for train in train_q_:\n",
    "    tags_tr, title_tr, songs_tr = train['tags'], train['plylst_title'], train['songs']\n",
    "    print(train)\n",
    "    tag_vec = np.mean([w2v_tag.wv[word_idx_tag[__]] \n",
    "                       for _ in tags_tr for __ in _\n",
    "                       if __ in w2v_tag])\n",
    "    title_vec = np.mean([w2v_title.wv[word_idx_title[__]] \n",
    "                         for _ in title_tr for __ in _\n",
    "                        if _ in w2v_title])\n",
    "    song_vec = np.mean([[w2v_song.wv[word_idx_song[__]] \n",
    "                         for _ in songs_tr \n",
    "]])\n",
    "    print(tag_vec, title_vec, song_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(use_song)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max([len(train['songs']) for train in train_q])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "This model has not yet been built. Build the model first by calling `build()` or calling `fit()` with some data, or specify an `input_shape` argument in the first layer(s) for automatic build.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-7cddb18d9c88>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/long36v/lib/python3.6/site-packages/tensorflow/python/keras/engine/network.py\u001b[0m in \u001b[0;36msummary\u001b[0;34m(self, line_length, positions, print_fn)\u001b[0m\n\u001b[1;32m   1344\u001b[0m     \"\"\"\n\u001b[1;32m   1345\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1346\u001b[0;31m       raise ValueError('This model has not yet been built. '\n\u001b[0m\u001b[1;32m   1347\u001b[0m                        \u001b[0;34m'Build the model first by calling `build()` or calling '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1348\u001b[0m                        \u001b[0;34m'`fit()` with some data, or specify '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: This model has not yet been built. Build the model first by calling `build()` or calling `fit()` with some data, or specify an `input_shape` argument in the first layer(s) for automatic build."
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(1000), input_shape=)\n",
    "model.\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "plylst_tag = plylst['tags']\n",
    "tag_counter = Counter([tg for tgs in plylst_tag for tg in tgs])\n",
    "tag_dict = {x: tag_counter[x] for x in tag_counter}\n",
    "\n",
    "tag_id_tid = dict()\n",
    "tag_tid_id = dict()\n",
    "for i, t in enumerate(tag_dict):\n",
    "    tag_id_tid[t] = i\n",
    "    tag_tid_id[i] = t\n",
    "\n",
    "n_tags = len(tag_dict)\n",
    "\n",
    "plylst_song = plylst['songs']\n",
    "#song_selected = [_[0] for _ in list(filter(lambda e: e[1] > 100, Counter(songs).items()))]\n",
    "song_counter = Counter([sg for sgs in plylst_song for sg in sgs])\n",
    "song_dict = {x: song_counter[x] for x in song_counter}\n",
    "\n",
    "song_dict_100 = {x: song_counter[x] for x in song_counter if song_counter[x]>100}\n",
    "song_dict_10_100 = {x: song_counter[x] for x in song_counter if 10 < song_counter[x] <= 100}\n",
    "song_dict_10 = {x: song_counter[x] for x in song_counter if song_counter[x]>10}\n",
    "song_dict_0_10 = {x: song_counter[x] for x in song_counter if song_counter[x] <= 10}\n",
    "song_dict_20 = {x: song_counter[x] for x in song_counter if song_counter[x]>20}\n",
    "\n",
    "song_id_sid = dict()\n",
    "song_sid_id = dict()\n",
    "\n",
    "song_100_id_sid = dict()\n",
    "song_100_sid_id = dict()\n",
    "\n",
    "song_10_id_sid = dict()\n",
    "song_10_sid_id = dict()\n",
    "\n",
    "song_20_id_sid = dict()\n",
    "song_20_sid_id = dict()\n",
    "\n",
    "song_10_100_id_sid = dict()\n",
    "song_10_100_sid_id = dict()\n",
    "\n",
    "song_0_10_id_sid = dict()\n",
    "song_0_10_sid_id = dict()\n",
    "\n",
    "for i, t in enumerate(song_dict):\n",
    "    song_id_sid[t] = i\n",
    "    song_sid_id[i] = t\n",
    "\n",
    "for i, t in enumerate(song_dict_100):\n",
    "    song_100_id_sid[t] = i\n",
    "    song_100_sid_id[i] = t\n",
    "\n",
    "for i, t in enumerate(song_dict_10):\n",
    "    song_10_id_sid[t] = i\n",
    "    song_10_sid_id[i] = t\n",
    "\n",
    "for i, t in enumerate(song_dict_20):\n",
    "    song_20_id_sid[t] = i\n",
    "    song_20_sid_id[i] = t\n",
    "\n",
    "for i, t in enumerate(song_dict_10_100):\n",
    "    song_10_100_id_sid[t] = i\n",
    "    song_10_100_sid_id[i] = t\n",
    "\n",
    "for i, t in enumerate(song_dict_0_10):\n",
    "    song_0_10_id_sid[t] = i\n",
    "    song_0_10_sid_id[i] = t\n",
    "\n",
    "\n",
    "n_songs = len(song_dict)\n",
    "n_songs_100 = len(song_dict_100)\n",
    "n_songs_10 = len(song_dict_10)\n",
    "n_songs_20 = len(song_dict_20)\n",
    "n_songs_10_100 = len(song_dict_10_100)\n",
    "n_songs_0_10 = len(song_dict_0_10)\n",
    "n_plylst = len(plylst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(615142, 8491, 66587, 540064)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_songs, n_songs_100, n_songs_10_100, n_songs_0_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "plylst['songs_id_10'] = plylst['songs'].map(lambda x: [song_10_id_sid.get(s) for s in x if song_10_id_sid.get(s) != None])\n",
    "plylst['songs_id_20'] = plylst['songs'].map(lambda x: [song_20_id_sid.get(s) for s in x if song_20_id_sid.get(s) != None])\n",
    "plylst['songs_id'] = plylst['songs'].map(lambda x: [song_id_sid.get(s) for s in x if song_id_sid.get(s) != None])\n",
    "plylst['songs_id_100'] = plylst['songs'].map(lambda x: [song_100_id_sid.get(s) for s in x if song_100_id_sid.get(s) != None])\n",
    "\n",
    "plylst['songs_id_10_100'] = plylst['songs'].map(lambda x: [song_10_100_id_sid.get(s) for s in x if song_10_100_id_sid.get(s) != None])\n",
    "plylst['songs_id_0_10'] = plylst['songs'].map(lambda x: [song_0_10_id_sid.get(s) for s in x if song_0_10_id_sid.get(s) != None])\n",
    "\n",
    "plylst['tags_id'] = plylst['tags'].map(lambda x: [tag_id_tid.get(t) for t in x if tag_id_tid.get(t) != None])\n",
    "\n",
    "plylst['songs_id_hier'] = plylst['songs'].map(lambda x: [[0,song_100_id_sid.get(s)] if song_100_id_sid.get(s) != None else [1,song_10_100_id_sid.get(s)] if song_10_100_id_sid.get(s) != None else [2,song_0_10_id_sid.get(s)] for s in x ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_list = plylst[plylst[\"songs_id_20\"].apply(lambda a: len(a)>0)*plylst[\"songs_id_20\"].apply(lambda a: len(a)>0)][\"songs_id_20\"].tolist()\n",
    "\n",
    "# train_list_100 = plylst[plylst[\"songs_id_100\"].apply(lambda a: len(a)>0)][\"songs_id_100\"].tolist()\n",
    "\n",
    "# train_list_10_100 = plylst[plylst[\"songs_id_10_100\"].apply(lambda a: len(a)>0)][\"songs_id_10_100\"].tolist()\n",
    "\n",
    "# train_list_0_10 = plylst[plylst[\"songs_id_0_10\"].apply(lambda a: len(a)>0)][\"songs_id_0_10\"].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_list = plylst[plylst['songs_id_hier'].apply(lambda a: 0 in np.array(a)[:,0] and 1 in np.array(a)[:,0] and 2 in np.array(a)[:,0])]['songs_id_hier'].tolist()\n",
    "\n",
    "train_list_a = plylst[plylst['songs_id_hier'].apply(lambda a: 0 in np.array(a)[:,0] and 1 in np.array(a)[:,0] and 2 in np.array(a)[:,0])]['songs_id'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(79409, 79409)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_list), len(train_list_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29160 615142\n"
     ]
    }
   ],
   "source": [
    "# print(n_songs_100)\n",
    "n_tags = len(tag_dict)\n",
    "print(n_tags, n_songs)\n",
    "#print(len(train_list_100),len(train_list_10_100),len(train_list_0_10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP5(\n",
       "  (song_embedding_100): Embedding(8491, 774)\n",
       "  (song_embedding_10_100): Embedding(66587, 387)\n",
       "  (song_embedding_0_10): Embedding(540064, 387)\n",
       "  (fc_layers): ModuleList(\n",
       "    (0): Linear(in_features=1548, out_features=512, bias=True)\n",
       "    (1): Linear(in_features=512, out_features=256, bias=True)\n",
       "  )\n",
       "  (output_layer): Linear(in_features=256, out_features=615142, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from models import *\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = MLP5(n_tags, n_songs_100, n_songs_10_100, n_songs_0_10, layers=[1548, 512, 256], dropout=False, use_cuda = True)\n",
    "if torch.cuda.device_count() > 1:\n",
    "    model = nn.DataParallel(model)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #from models import MLP\n",
    "# os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'\n",
    "# # device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# model = MLP(n_tags, n_songs_20, layers=[4096, 2048, 6192], dropout=False, use_cuda = True)\n",
    "# if torch.cuda.device_count() > 1:\n",
    "#     model = nn.DataParallel(model)\n",
    "# model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(\"./output_model_epoch_0.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(checkpoint['model_state_dict'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP4(\n",
       "  (song_embedding): Embedding(42109, 1024)\n",
       "  (fc_layers): ModuleList(\n",
       "    (0): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    (1): Linear(in_features=512, out_features=256, bias=True)\n",
       "    (2): Linear(in_features=256, out_features=512, bias=True)\n",
       "    (3): Linear(in_features=512, out_features=256, bias=True)\n",
       "    (4): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (5): Linear(in_features=128, out_features=256, bias=True)\n",
       "    (6): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (7): Linear(in_features=128, out_features=256, bias=True)\n",
       "    (8): Linear(in_features=256, out_features=512, bias=True)\n",
       "    (9): Linear(in_features=512, out_features=256, bias=True)\n",
       "    (10): Linear(in_features=256, out_features=512, bias=True)\n",
       "    (11): Linear(in_features=512, out_features=256, bias=True)\n",
       "    (12): Linear(in_features=256, out_features=512, bias=True)\n",
       "    (13): Linear(in_features=512, out_features=256, bias=True)\n",
       "    (14): Linear(in_features=256, out_features=512, bias=True)\n",
       "    (15): Linear(in_features=512, out_features=256, bias=True)\n",
       "    (16): Linear(in_features=256, out_features=512, bias=True)\n",
       "    (17): Linear(in_features=512, out_features=1024, bias=True)\n",
       "    (18): Linear(in_features=1024, out_features=2048, bias=True)\n",
       "    (19): Linear(in_features=2048, out_features=4096, bias=True)\n",
       "  )\n",
       "  (output_layer): Linear(in_features=4096, out_features=42109, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from models import *\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = MLP4(n_tags, n_songs_20, layers=[1024, 512, 256, 512, 256, 128, 256, 128, 256, 512, 256, 512, 256, 512, 256, 512, 256, 512, 1024, 2048, 4096], dropout=False, use_cuda = True)\n",
    "if torch.cuda.device_count() > 1:\n",
    "    model = nn.DataParallel(model)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP2(\n",
       "  (song_embedding): Embedding(42109, 1024)\n",
       "  (fc_layers): ModuleList(\n",
       "    (0): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    (1): Linear(in_features=512, out_features=256, bias=True)\n",
       "    (2): Linear(in_features=256, out_features=512, bias=True)\n",
       "    (3): Linear(in_features=512, out_features=256, bias=True)\n",
       "    (4): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (5): Linear(in_features=128, out_features=256, bias=True)\n",
       "    (6): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (7): Linear(in_features=128, out_features=256, bias=True)\n",
       "    (8): Linear(in_features=256, out_features=512, bias=True)\n",
       "    (9): Linear(in_features=512, out_features=256, bias=True)\n",
       "    (10): Linear(in_features=256, out_features=512, bias=True)\n",
       "    (11): Linear(in_features=512, out_features=256, bias=True)\n",
       "    (12): Linear(in_features=256, out_features=512, bias=True)\n",
       "    (13): Linear(in_features=512, out_features=256, bias=True)\n",
       "    (14): Linear(in_features=256, out_features=512, bias=True)\n",
       "    (15): Linear(in_features=512, out_features=256, bias=True)\n",
       "    (16): Linear(in_features=256, out_features=512, bias=True)\n",
       "    (17): Linear(in_features=512, out_features=1024, bias=True)\n",
       "    (18): Linear(in_features=1024, out_features=2048, bias=True)\n",
       "  )\n",
       "  (output_layer): Linear(in_features=2048, out_features=42109, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from models import MLP1\n",
    "from models import *\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = MLP2(n_tags, n_songs_20, layers=[1024, 512, 256, 512, 256, 128, 256, 128, 256, 512, 256, 512, 256, 512, 256, 512, 256, 512, 1024, 2048], dropout=False, use_cuda = True)\n",
    "if torch.cuda.device_count() > 1:\n",
    "    model = nn.DataParallel(model)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "# Dataset 상속\n",
    "class CustomDataset(Dataset): \n",
    "  def __init__(self, xinput, yinput):\n",
    "    self.x_data = xinput\n",
    "    self.y_data = yinput\n",
    "    # self.batch_size = batchsize\n",
    "\n",
    "  # 총 데이터의 개수를 리턴\n",
    "  def __len__(self): \n",
    "    return len(self.x_data)\n",
    "\n",
    "  # 인덱스를 입력받아 그에 맵핑되는 입출력 데이터를 파이토치의 Tensor 형태로 리턴\n",
    "  def __getitem__(self, idx): \n",
    "    # device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    # x = torch.LongTensor(self.x_data[idx]).to(device)\n",
    "    # y = torch.LongTensor(self.y_data[idx]).to(device)\n",
    "    x = torch.LongTensor(self.x_data[idx])\n",
    "    y = torch.LongTensor(self.y_data[idx])\n",
    "    return {\"input\": x, \"label\": y}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_batch(samples):\n",
    "    inputs = [sample['input'] for sample in samples]\n",
    "    inputs = torch.nn.utils.rnn.pad_sequence(inputs, batch_first=True, padding_value = n_songs_20)\n",
    "    labels = [sample['label'] for sample in samples]\n",
    "    labels = torch.nn.utils.rnn.pad_sequence(labels, batch_first=True, padding_value = n_songs_20)\n",
    "    # padded_inputs = torch.nn.utils.rnn.pad_sequence(inputs, batch_first=True)\n",
    "    return {'input': inputs,\n",
    "            'label': labels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = CustomDataset(train_list, train_list_a)\n",
    "dataloader = DataLoader(input, batch_size=1, collate_fn=make_batch, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 798.00 MiB (GPU 0; 11.00 GiB total capacity; 9.37 GiB already allocated; 346.50 MiB free; 9.40 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-f02dc5464bf1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m                  \u001b[0mrecord_loss_every\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                  use_cuda = True)\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\hscho\\coldmelon\\autoencoder\\training.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, data_loader, epochs, save_training_gif)\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m             \u001b[0mepoch_train_start\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m             \u001b[0mmean_epoch_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmean_epoch_ndcg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmean_epoch_loss_recon\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmean_epoch_loss_embed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_epoch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     76\u001b[0m             print('Epoch: {} Average loss: {:.2f} Average ndcg: {:.2f} Average recon_loss: {:.2f} Average embed_loss: {:.2f} Training time: {:.2f}'.format(epoch + 1,\n\u001b[0;32m     77\u001b[0m                                                           \u001b[0mmean_epoch_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmean_epoch_ndcg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmean_epoch_loss_recon\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmean_epoch_loss_embed\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\hscho\\coldmelon\\autoencoder\\training.py\u001b[0m in \u001b[0;36m_train_epoch\u001b[1;34m(self, data_loader)\u001b[0m\n\u001b[0;32m    108\u001b[0m             \u001b[1;31m# data = data.to(device)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m             \u001b[1;31m# label = label.to(device)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 110\u001b[1;33m             \u001b[0miter_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mndcg_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miter_loss_recon\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miter_loss_embed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_iteration\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdatas\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    111\u001b[0m             \u001b[0mepoch_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0miter_loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m             \u001b[0mepoch_ndcg\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mndcg_loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\hscho\\coldmelon\\autoencoder\\training.py\u001b[0m in \u001b[0;36m_train_iteration\u001b[1;34m(self, datas)\u001b[0m\n\u001b[0;32m    169\u001b[0m         \u001b[0mndcg_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ndcg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moutput_recon\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    170\u001b[0m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 171\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    172\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m         \u001b[0mtrain_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\myvae\\lib\\site-packages\\torch\\optim\\adam.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    101\u001b[0m                     \u001b[0mdenom\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmax_exp_avg_sq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'eps'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 103\u001b[1;33m                     \u001b[0mdenom\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mexp_avg_sq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'eps'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m                 \u001b[0mstep_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'lr'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mbias_correction1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 798.00 MiB (GPU 0; 11.00 GiB total capacity; 9.37 GiB already allocated; 346.50 MiB free; 9.40 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(model, optimizer, n_songs_100 + n_songs_10_100 + n_songs_0_10,\n",
    "                 print_loss_every=100,\n",
    "                 record_loss_every=5,\n",
    "                 use_cuda = True)\n",
    "trainer.train(dataloader, epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({'epoch': 0, 'model_state_dict': model.state_dict(), 'optimizer_state_dict': optimizer.state_dict()},\"./output_model_epoch_0.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_json = load_json('../file/val.json')\n",
    "val_json_1 = load_json(\"../file/results.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_seen(seen, l):\n",
    "    seen = set(seen)\n",
    "    return [x for x in l if not (x in seen)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "500\n",
      "1000\n",
      "1500\n",
      "2000\n",
      "2500\n",
      "3000\n",
      "3500\n",
      "4000\n",
      "4500\n",
      "5000\n",
      "5500\n",
      "6000\n",
      "6500\n",
      "7000\n",
      "7500\n",
      "8000\n",
      "8500\n",
      "9000\n",
      "9500\n",
      "10000\n",
      "10500\n",
      "11000\n",
      "11500\n",
      "12000\n",
      "12500\n",
      "13000\n",
      "13500\n",
      "14000\n",
      "14500\n",
      "15000\n",
      "15500\n",
      "16000\n",
      "16500\n",
      "17000\n",
      "17500\n",
      "18000\n",
      "18500\n",
      "19000\n",
      "19500\n",
      "20000\n",
      "20500\n",
      "21000\n",
      "21500\n",
      "22000\n",
      "22500\n",
      "23000\n"
     ]
    }
   ],
   "source": [
    "for idx, plst in enumerate(val_json):\n",
    "    if len(plst['songs']) !=0 :\n",
    "        tmp=np.array(list(map(lambda s: [0,song_100_id_sid.get(s)] if song_100_id_sid.get(s) != None else [1,song_10_100_id_sid.get(s)] if song_10_100_id_sid.get(s) != None else [2,song_0_10_id_sid.get(s)] if song_0_10_id_sid.get(s) != None else [615142,615142], plst['songs'])))\n",
    "        ipp = [torch.from_numpy(tmp[tmp!=[615142,615142]].reshape(-1,2)).to(dtype = torch.long, device = device)]\n",
    "        #print(ipp.shape)\n",
    "        output = model.predict(ipp)\n",
    "        rec_song_idx = [song_sid_id[i] for i in output]\n",
    "        rec_song_idx = remove_seen(plst['songs'],rec_song_idx)\n",
    "        rec_song_idx = rec_song_idx[:100]\n",
    "        val_json_1[idx]['songs']=rec_song_idx\n",
    "    if idx % 500 == 0 :\n",
    "        print(idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([375205, 403509, 302814, 577464, 110804, 120282,  53468, 429662,\n",
       "        46894, 187353,  84157,  24355, 313185, 104931, 451993, 307118,\n",
       "       182369, 450387, 377740, 595349, 543041,  58227, 471478, 605504,\n",
       "        28907, 406451, 529940, 524900, 106554, 397420,  37860, 146677,\n",
       "       114593, 126908, 581766, 502784, 291339, 423164,  85924, 152538,\n",
       "       409752, 226754,      0,  95480, 304912, 444864,  84648, 556605,\n",
       "       387161, 431915, 566758, 136839, 212922,  37388, 187268, 557458,\n",
       "       345563, 434584, 101344, 375776, 213192, 610982, 548901, 598822,\n",
       "       235126, 466859, 145443, 366366, 449636, 281114, 514351, 348241,\n",
       "       588003, 289977, 450049, 510930, 178832, 367905, 372123, 279450,\n",
       "       523010, 556609, 594090, 520071,  79168, 515996, 452334, 514259,\n",
       "       242194, 475587, 167449, 584090, 273474,  34799, 474495,      1,\n",
       "       197197, 288069, 127896, 593605, 359027, 445257, 419149, 503400,\n",
       "       214592, 322273, 568653, 597565, 461940, 297482, 385187, 220822,\n",
       "       490448, 430910, 302640, 538554, 513327, 240424,  40300, 513119,\n",
       "       563584, 563658, 192900, 195891, 262561, 482831, 576574, 179003,\n",
       "       507455, 228889, 610502, 104264,  66891, 555177, 310127, 193182,\n",
       "       412778, 510991, 288304, 312230, 136871,      2, 303363, 481681,\n",
       "       152297,      3, 423853, 578293, 313772,  95823, 148735, 301298,\n",
       "       587404, 106885, 183722, 156134, 373736, 331067, 513099, 186397,\n",
       "       357011, 249684, 384212, 613553, 493319, 473163,  88046, 614515,\n",
       "       147565, 265451,  67937, 531548, 173111, 184112, 538501, 534575,\n",
       "            4, 609858, 338337, 571735,  91227, 415660, 228712, 463072,\n",
       "       303463, 493066, 376637,  54435, 278631, 197751, 193483,  73328,\n",
       "       613824, 210144, 125398, 127394, 575469, 375765, 580098,  53730],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[    0,  4299],\n",
       "         [    0,  1498],\n",
       "         [    0,  3404],\n",
       "         [    0,  5061],\n",
       "         [    0,  2919],\n",
       "         [    0,  1506],\n",
       "         [    0,  1518],\n",
       "         [    0,  2252],\n",
       "         [    0,  2870],\n",
       "         [    1, 18259],\n",
       "         [    1, 20741],\n",
       "         [    0,  1513],\n",
       "         [    0,  1514],\n",
       "         [    1, 28290],\n",
       "         [    0,   522],\n",
       "         [    0,  6394],\n",
       "         [    0,  7331],\n",
       "         [    0,  1270],\n",
       "         [    0,  1497],\n",
       "         [    0,  7686]], device='cuda:0')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ipp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_json(val_json_1, \"./year_genre_onehot/results.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[     1,  17608],\n",
      "         [     0,   5097],\n",
      "         [     2,   2474],\n",
      "         [     2, 480139],\n",
      "         [     2, 390715],\n",
      "         [     2, 480140],\n",
      "         [     2, 480141],\n",
      "         [     2, 480142],\n",
      "         [     2, 480143],\n",
      "         [     1,  33522],\n",
      "         [     2, 480144],\n",
      "         [     2, 480145],\n",
      "         [     2, 480146],\n",
      "         [     2, 411721]]])\n",
      "1\n",
      "=======\n",
      "tensor([[ 39421,  18188,   9378, 555217, 465793, 555218, 555219, 555220, 555221,\n",
      "          76691, 555222, 555223, 555224, 486799]])\n"
     ]
    }
   ],
   "source": [
    "for x in dataloader:\n",
    "    data, label = x['input'], x['label']\n",
    "    print(data)\n",
    "    print(len(data))\n",
    "    print(\"=======\")\n",
    "    print(label)\n",
    "    break   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, plst in enumerate(val_json):\n",
    "    if len(plst['songs']) !=0 :\n",
    "        tmp=np.array(list(map(lambda s: [0,song_100_id_sid.get(s)] if song_100_id_sid.get(s) != None else [1,song_10_100_id_sid.get(s)] if song_10_100_id_sid.get(s) != None else [2,song_0_10_id_sid.get(s)] if song_0_10_id_sid.get(s) != None else [615142,615142], plst['songs'])))\n",
    "        torch.from_numpy(tmp[tmp!=[615142,615142]].reshape(-1,2)).to(dtype = torch.long, device = device)\n",
    "    if idx == 5:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, plst in enumerate(val_json):\n",
    "    if len(plst['songs']) !=0 :\n",
    "        ipp = np.array([[song_20_id_sid.get(i) for i in val_json[idx]['songs'] if song_20_id_sid.get(i) != None]])\n",
    "        output = model.predict(ipp)\n",
    "        output = output[np.isin(output, ipp[0]) == False][:100]\n",
    "        rec_song_idx = [song_20_sid_id[i] for i in output]\n",
    "        val_json_1[idx]['songs']=rec_song_idx\n",
    "    if idx % 500 == 0 :\n",
    "        print(idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# CUDA for PyTorch\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "# cudnn.benchmark = True\n",
    "\n",
    "\n",
    "def main():\n",
    "\n",
    "    args = parse_args()\n",
    "    path = args.path\n",
    "    dataset = args.dataset\n",
    "    layers = eval(args.layers)\n",
    "    weight_decay = args.weight_decay\n",
    "    num_negatives_train = args.num_neg_train\n",
    "    num_negatives_test = args.num_neg_test\n",
    "    dropout = args.dropout\n",
    "    learner = args.learner\n",
    "    learning_rate = args.lr\n",
    "    batch_size = args.batch_size\n",
    "    epochs = args.epochs\n",
    "    verbose = args.verbose\n",
    "\n",
    "    topK = 100\n",
    "    print(\"MLP arguments: %s \" % (args))\n",
    "    # model_out_file = 'Pretrain/%s_MLP_%s_%d.h5' %(args.dataset, args.layers, time())\n",
    "\n",
    "    # Load data\n",
    "\n",
    "    t1 = time()\n",
    "    full_dataset = CustomDataset(train_q_list, train_a_list)\n",
    "\n",
    "    train_data_q, train_data_a = full_dataset.x_data, full_dataset.y_data\n",
    "    num_data = len(full_dataset)\n",
    "\n",
    "    print(\"Load data done [%.1f s]. #user=%d, #item=%d\"\n",
    "          % (time()-t1, num_data, n_songs_100))\n",
    "    \n",
    "    #dataloader = DataLoader(dataset, batch_size=2, shuffle=True)\n",
    "    \n",
    "    training_data_generator = DataLoader(\n",
    "        full_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "\n",
    "    # Build model\n",
    "    model = MLP(num_data, n_songs_100, layers=layers, dropout=dropout)\n",
    "    # Transfer the model to GPU, if one is available\n",
    "    model.to(device)\n",
    "    if verbose:\n",
    "        print(model)\n",
    "\n",
    "    loss_fn = torch.nn.BCELoss()\n",
    "    # Use Adam optimizer\n",
    "    optimizer = torch.optim.Adam(model.parameters(), weight_decay=weight_decay)\n",
    "\n",
    "    # Record performance\n",
    "    hr_list = []\n",
    "    ndcg_list = []\n",
    "    BCE_loss_list = []\n",
    "\n",
    "    # Check Init performance\n",
    "    hr, ndcg = test(model, full_dataset, topK)\n",
    "    hr_list.append(hr)\n",
    "    ndcg_list.append(ndcg)\n",
    "    BCE_loss_list.append(1)\n",
    "    # do the epochs now\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss = train_one_epoch( model, training_data_generator, loss_fn, optimizer, epoch, device)\n",
    "\n",
    "        if epoch % verbose == 0:\n",
    "            hr, ndcg = test(model, full_dataset, topK)\n",
    "            hr_list.append(hr)\n",
    "            ndcg_list.append(ndcg)\n",
    "            BCE_loss_list.append(epoch_loss)\n",
    "            # if hr > best_hr:\n",
    "            #     best_hr, best_ndcg, best_iter = hr, ndcg, epoch\n",
    "            #     if args.out > 0:\n",
    "            #         model.save(model_out_file, overwrite=True)\n",
    "    print(\"hr for epochs: \", hr_list)\n",
    "    print(\"ndcg for epochs: \", ndcg_list)\n",
    "    print(\"loss for epochs: \", BCE_loss_list)\n",
    "    # plot_statistics(hr_list, ndcg_list, BCE_loss_list,model.get_alias(), \"./figs\")\n",
    "    # with open(\"metrics\", 'wb') as fp:\n",
    "    #     pickle.dump(hr_list, fp)\n",
    "    #     pickle.dump(ndcg_list, fp)\n",
    "\n",
    "    best_iter = np.argmax(np.array(hr_list))\n",
    "    best_hr = hr_list[best_iter]\n",
    "    best_ndcg = ndcg_list[best_iter]\n",
    "    print(\"End. Best Iteration %d:  HR = %.4f, NDCG = %.4f. \" %\n",
    "          (best_iter, best_hr, best_ndcg))\n",
    "    # if args.out > 0:\n",
    "    #     print(\"The best MLP model is saved to %s\" %(model_out_file))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Device available: {}\".format(device))\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

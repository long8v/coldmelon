{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "import json\n",
    "import distutils.dir_util\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def write_json(data, fname):\n",
    "    def _conv(o):\n",
    "        if isinstance(o, np.int64) or isinstance(o, np.int32):\n",
    "            return int(o)\n",
    "        raise TypeError\n",
    "\n",
    "    parent = os.path.dirname(fname)\n",
    "    distutils.dir_util.mkpath(\"./\" + parent)\n",
    "    with io.open(\"./\" + fname, \"w\", encoding=\"utf8\") as f:\n",
    "        json_str = json.dumps(data, ensure_ascii=False, default=_conv)\n",
    "        f.write(json_str)\n",
    "\n",
    "\n",
    "def load_json(fname):\n",
    "    with open(fname, encoding='utf8') as f:\n",
    "        json_obj = json.load(f)\n",
    "\n",
    "    return json_obj\n",
    "\n",
    "\n",
    "def debug_json(r):\n",
    "    print(json.dumps(r, ensure_ascii=False, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as spr\n",
    "from collections import Counter\n",
    "from scipy.sparse import hstack, vstack\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "def remove_seen(seen, l):\n",
    "    seen = set(seen)\n",
    "    return [x for x in l if not (x in seen)]\n",
    "\n",
    "\n",
    "def most_popular(playlists, col, topk_count):\n",
    "    c = Counter()\n",
    "\n",
    "    for doc in playlists:\n",
    "        c.update(doc[col])\n",
    "\n",
    "    topk = c.most_common(topk_count)\n",
    "    return c, [k for k, v in topk]\n",
    "\n",
    "song_meta = pd.read_json(\"./data/song_meta.json\")\n",
    "train = pd.read_json(\"./data/train.json\")\n",
    "test = pd.read_json(\"./data/test.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['istrain'] = 1\n",
    "test['istrain'] = 0\n",
    "\n",
    "n_train = len(train)\n",
    "n_test = len(test)\n",
    "\n",
    "# train + test\n",
    "plylst = pd.concat([train, test], ignore_index=True)\n",
    "\n",
    "# playlist id\n",
    "plylst[\"nid\"] = range(n_train + n_test)\n",
    "\n",
    "# id <-> nid\n",
    "plylst_id_nid = dict(zip(plylst[\"id\"],plylst[\"nid\"]))\n",
    "plylst_nid_id = dict(zip(plylst[\"nid\"],plylst[\"id\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "plylst_tag = plylst['tags']\n",
    "tag_counter = Counter([tg for tgs in plylst_tag for tg in tgs])\n",
    "tag_dict = {x: tag_counter[x] for x in tag_counter}\n",
    "\n",
    "tag_id_tid = dict()\n",
    "tag_tid_id = dict()\n",
    "for i, t in enumerate(tag_dict):\n",
    "    tag_id_tid[t] = i\n",
    "    tag_tid_id[i] = t\n",
    "\n",
    "n_tags = len(tag_dict)\n",
    "\n",
    "plylst_song = plylst['songs']\n",
    "song_counter = Counter([sg for sgs in plylst_song for sg in sgs])\n",
    "song_dict = {x: song_counter[x] for x in song_counter}\n",
    "\n",
    "song_id_sid = dict()\n",
    "song_sid_id = dict()\n",
    "for i, t in enumerate(song_dict):\n",
    "    song_id_sid[t] = i\n",
    "    song_sid_id[i] = t\n",
    "\n",
    "n_songs = len(song_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonghyunlee/anaconda3/envs/coldmelon/lib/python3.6/site-packages/pandas/core/indexing.py:845: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "/Users/jonghyunlee/anaconda3/envs/coldmelon/lib/python3.6/site-packages/pandas/core/indexing.py:966: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "plylst['songs_id'] = plylst['songs'].map(lambda x: [song_id_sid.get(s) for s in x if song_id_sid.get(s) != None])\n",
    "plylst['tags_id'] = plylst['tags'].map(lambda x: [tag_id_tid.get(t) for t in x if tag_id_tid.get(t) != None])\n",
    "\n",
    "plylst_use = plylst[['istrain','nid','updt_date','songs_id','tags_id']]\n",
    "\n",
    "# 곡의 개수와 태그의 개수를 할당\n",
    "plylst_use.loc[:,'num_songs'] = plylst_use['songs_id'].map(len)\n",
    "plylst_use.loc[:,'num_tags'] = plylst_use['tags_id'].map(len)\n",
    "plylst_use = plylst_use.set_index('nid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "plylst_train = plylst_use.iloc[:n_train,:]\n",
    "plylst_test = plylst_use.iloc[n_train:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# csr (compressed sparse row matrix 생성)\n",
    "row = np.repeat(range(n_train), plylst_train['num_songs'])\n",
    "col = [song for songs in plylst_train['songs_id'] for song in songs]\n",
    "dat = np.repeat(1, plylst_train['num_songs'].sum())\n",
    "train_songs_A = spr.csr_matrix((dat, (row, col)), shape=(n_train, n_songs))\n",
    "\n",
    "row = np.repeat(range(n_train), plylst_train['num_tags'])\n",
    "col = [tag for tags in plylst_train['tags_id'] for tag in tags]\n",
    "dat = np.repeat(1, plylst_train['num_tags'].sum())\n",
    "train_tags_A = spr.csr_matrix((dat, (row, col)), shape=(n_train, n_tags))\n",
    "\n",
    "# csr (compressed sparse row matrix 생성)\n",
    "row = np.repeat(range(n_test), plylst_test['num_songs'])\n",
    "col = [song for songs in plylst_test['songs_id'] for song in songs]\n",
    "dat = np.repeat(1, plylst_test['num_songs'].sum())\n",
    "test_songs_A = spr.csr_matrix((dat, (row, col)), shape=(n_test, n_songs))\n",
    "\n",
    "row = np.repeat(range(n_test), plylst_test['num_tags'])\n",
    "col = [tag for tags in plylst_test['tags_id'] for tag in tags]\n",
    "dat = np.repeat(1, plylst_test['num_tags'].sum())\n",
    "test_tags_A = spr.csr_matrix((dat, (row, col)), shape=(n_test, n_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_merged_feature_csr = hstack([train_songs_A, train_tags_A])\n",
    "test_merged_feature_csr  = hstack([test_songs_A, test_tags_A])\n",
    "\n",
    "train_songs_A_T = train_songs_A.T.tocsr()\n",
    "train_tags_A_T  = train_tags_A.T.tocsr()\n",
    "\n",
    "whole_datasets_csr       = vstack([train_merged_feature_csr, test_merged_feature_csr])\n",
    "whole_datasets_csr_T     = whole_datasets_csr.T.tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(656082, 125811)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "whole_datasets_csr_T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbb06c59bef24763b03809d46a166945",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10740.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def rec(pids):\n",
    "    res = []\n",
    "\n",
    "    for pid in tqdm(pids):\n",
    "        p = np.zeros((n_songs,1))\n",
    "        p[plylst_test.loc[pid,'songs_id']] = 1\n",
    "\n",
    "        val = train_songs_A.dot(p).reshape(-1)\n",
    "\n",
    "        songs_already = plylst_test.loc[pid, \"songs_id\"]\n",
    "        tags_already = plylst_test.loc[pid, \"tags_id\"]\n",
    "\n",
    "        cand_song = train_songs_A_T.dot(val)\n",
    "        cand_song_idx = cand_song.reshape(-1).argsort()[-250:][::-1]\n",
    "\n",
    "        cand_song_idx = cand_song_idx[np.isin(cand_song_idx, songs_already) == False][:100]\n",
    "        rec_song_idx = [song_sid_id[i] for i in cand_song_idx]\n",
    "\n",
    "        cand_tag = train_tags_A_T.dot(val)\n",
    "        cand_tag_idx = cand_tag.reshape(-1).argsort()[-15:][::-1]\n",
    "\n",
    "        cand_tag_idx = cand_tag_idx[np.isin(cand_tag_idx, tags_already) == False][:10]\n",
    "        rec_tag_idx = [tag_tid_id[i] for i in cand_tag_idx]\n",
    "\n",
    "        res.append({\n",
    "            \"id\": plylst_nid_id[pid],\n",
    "            \"songs\": rec_song_idx,\n",
    "            \"tags\": rec_tag_idx\n",
    "        })\n",
    "        \n",
    "    return res\n",
    "\n",
    "res = rec(plylst_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir(\"final_results\")\n",
    "write_json(res, \"./final_results/results_MF.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from gensim.models.keyedvectors import WordEmbeddingsKeyedVectors\n",
    "\n",
    "class PlaylistEmbedding:\n",
    "    def __init__(self, FILE_PATH):\n",
    "        self.FILE_PATH = FILE_PATH\n",
    "        self.min_count = 3\n",
    "        self.size = 300\n",
    "        self.window = 300\n",
    "        self.sg = 5\n",
    "        self.p2v_model = WordEmbeddingsKeyedVectors(self.size)\n",
    "        with open(os.path.join(FILE_PATH, 'train.json'), encoding=\"utf-8\") as f:\n",
    "            self.train = json.load(f)\n",
    "        with open(os.path.join(FILE_PATH, 'test.json'), encoding=\"utf-8\") as f:\n",
    "            self.val = json.load(f)\n",
    "        with open(os.path.join(\"./final_results/\", 'results_MF.json'), encoding=\"utf-8\") as f:\n",
    "            self.most_results = json.load(f)\n",
    "            \n",
    "    def get_dic(self, train, val):\n",
    "        song_dic = {}\n",
    "        tag_dic = {}\n",
    "        data = train + val\n",
    "        for q in tqdm(data):\n",
    "            song_dic[str(q['id'])] = q['songs']\n",
    "            tag_dic[str(q['id'])] = q['tags']\n",
    "        self.song_dic = song_dic\n",
    "        self.tag_dic = tag_dic\n",
    "        total = list(map(lambda x: list(map(str, x['songs'])) + list(x['tags']), data))\n",
    "        total = [x for x in total if len(x)>1]\n",
    "        self.total = total\n",
    "        \n",
    "    def get_w2v(self, total, min_count, size, window, sg):\n",
    "        w2v_model = Word2Vec(total, min_count = min_count, size = size, window = window, sg = sg)\n",
    "        self.w2v_model = w2v_model\n",
    "            \n",
    "    def update_p2v(self, train, val, w2v_model):\n",
    "        ID = []   \n",
    "        vec = []\n",
    "        for q in tqdm(train + val):\n",
    "            tmp_vec = 0\n",
    "            if len(q['songs'])>=1:\n",
    "                for song in q['songs'] + q['tags']:\n",
    "                    try: \n",
    "                        tmp_vec += w2v_model.wv.get_vector(str(song))\n",
    "                    except KeyError:\n",
    "                        pass\n",
    "            if type(tmp_vec)!=int:\n",
    "                ID.append(str(q['id']))    \n",
    "                vec.append(tmp_vec)\n",
    "        self.p2v_model.add(ID, vec)\n",
    "    \n",
    "    def get_result(self, p2v_model, song_dic, tag_dic, most_results, val):\n",
    "        answers = []\n",
    "        for n, q in tqdm(enumerate(val), total = len(val)):\n",
    "            try:\n",
    "                most_id = [x[0] for x in p2v_model.most_similar(str(q['id']), topn=200)]\n",
    "                get_song = []\n",
    "                get_tag = []\n",
    "                for ID in most_id:\n",
    "                    get_song += song_dic[ID]\n",
    "                    get_tag += tag_dic[ID]\n",
    "                get_song = list(pd.value_counts(get_song)[:200].index)\n",
    "                get_tag = list(pd.value_counts(get_tag)[:20].index)\n",
    "                answers.append({\n",
    "                    \"id\": q[\"id\"],\n",
    "                    \"songs\": remove_seen(q[\"songs\"], get_song)[:100],\n",
    "#                     \"songs\": most_results[n]['songs'][:100],\n",
    "                    \"tags\": remove_seen(q[\"tags\"], get_tag)[:10],\n",
    "                })\n",
    "            except:\n",
    "                answers.append({\n",
    "                  \"id\": most_results[n][\"id\"],\n",
    "                  \"songs\": most_results[n]['songs'],\n",
    "                  \"tags\": most_results[n][\"tags\"],\n",
    "                }) \n",
    "        # check and update answer\n",
    "        for n, q in enumerate(answers):\n",
    "            if len(q['songs'])!=100:\n",
    "                answers[n]['songs'] += remove_seen(q['songs'], self.most_results[n]['songs'])[:100-len(q['songs'])]\n",
    "            if len(q['tags'])!=10:\n",
    "                answers[n]['tags'] += remove_seen(q['tags'], self.most_results[n]['tags'])[:10-len(q['tags'])]  \n",
    "        self.answers = answers\n",
    "    \n",
    "    def run(self):\n",
    "        self.get_dic(self.train, self.val)\n",
    "        self.get_w2v(self.total, self.min_count, self.size, self.window, self.sg)\n",
    "        self.update_p2v(self.train, self.val, self.w2v_model)\n",
    "        self.get_result(self.p2v_model, self.song_dic, self.tag_dic, self.most_results, self.val)\n",
    "        write_json(self.answers, 'results.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c371184f028440e380f735eddf8dcd4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=125811.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6553de85a9947a4aab8a7cf9569105c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=125811.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "612cea83c0b44691a49fe5949b7911f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10740.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "FILE_PATH = './data/'\n",
    "item2vec = PlaylistEmbedding(FILE_PATH)\n",
    "item2vec.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
